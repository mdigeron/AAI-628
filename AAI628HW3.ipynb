{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Zvz--F6PAxMf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "D9pRoZ1-Pkwm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "plt.subplot(221)\n",
        "plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "puj_DB7sQiUL",
        "outputId": "83a99842-c9f4-4189-e432-1d1c303a72cd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAGfCAYAAABhicrFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+SUlEQVR4nO3de1BUZ5o/8C8oNKDQiAhNKyiJGpPxtmuUEI2jkRWZWSdGZjeJqZROMnFiwB1lUkmYX2ImyUyRmKnEMmG0andGYu0YM1Z5KU1C1hDFyQq6El3GNSFKUDFcvESai9yE8/vDskf0fZSDp+m3u7+fqlMlXw6n39PSz0t3P+ftIMMwDBAREZHXBXt7AERERHQFJ2UiIiJNcFImIiLSBCdlIiIiTXBSJiIi0gQnZSIiIk1wUiYiItIEJ2UiIiJNcFImIiLSBCdlIiIiTQz01IHz8/Px1ltvoa6uDpMmTcK7776LadOm3fLnuru7UVNTg8jISAQFBXlqeER9YhgGmpqa4HQ6ERzMv2mt1te6AbB2kN56XTsMD9i8ebMRGhpq/OlPfzL+7//+z3j66aeN6Ohoo76+/pY/W11dbQDgxk3rrbq62hMPnYB2O3XDMFg7uPnGdqvaEWQY1n8gRUpKCqZOnYr33nsPwJW/YBMTE7F8+XK8+OKLN/1Zl8uF6Ohoq4dEZKmGhgbY7XZvD8Ov3E7dAAKzdowZM0aZ//73v1fm27dvV+bl5eXKvKOjQ5l3dnYq83vuuUeZ//M//7Myr6qqUuZr165V5i6XS5n7klvVDstfvu7o6EBZWRlyc3PdWXBwMNLS0lBSUnLD/u3t7Whvb3d/3dTUZPWQiCzHl0etZbZuAHrVDun3wQPPeXoYMGCAMh80aJAyDw0NNXUcKe/u7lbmISEhyjwiIkKZh4WFKXN/fnzd6twsf1Ps/Pnz6OrqQnx8fI88Pj4edXV1N+yfl5cHu93u3hITE60eEhFpzmzdAFg7yD95vVMlNzcXLpfLvVVXV3t7SETkA1g7yB9Z/vJ1bGwsBgwYgPr6+h55fX09HA7HDfvbbDbYbDarh0FEPsRs3QBYO8g/WT4ph4aGYsqUKSgqKsKCBQsAXHn/oaioCNnZ2VbfHBH5Ad3qhtn3iM2+dzx58mRl/uijjyrzzMxMZd7V1aXMpfeUf/e73ynzoUOHKnOrfPPNN8p80qRJyvza3oJrXf9H21WffvqpMpca3o4eParMdeCR65RzcnKwePFi3HvvvZg2bRrWrFmDlpYW/OxnP/PEzRGRH2DdIPLQpPzII4/g3LlzWLVqFerq6jB58mQUFhbe0MRBRHQV6waRB1f0ys7O5svVRGQK6wYFOq93XxMREdEVnJSJiIg04ZFlNm9HY2Mjly8k7blcLkRFRXl7GHQNb9YO6Xdh48aNynzixInKXPqgAmm1sra2NmUuLYMpdWtLK3FJ92dLS4syl1b6smqakVYACw8PV+bSCmZ//etflfkTTzzRt4GZcKvawWfKREREmuCkTEREpAlOykRERJrgpExERKQJTspERESa8NjiIeQ5Vn12a2RkpDKfMWOGMv/kk09MHV8ap/QZrZcvXzZ1fLPMfkarZhcmkMa2bt2qzEeOHKnMz549q8yl7uWBA9WlWnrMSL/r0nGk/c+fP6/MpcewROoqN6u1tVWZS13o0mN45syZynzcuHHK/Ouvv+7F6KzBZ8pERESa4KRMRESkCU7KREREmuCkTEREpAlOykRERJpg97UPkjoZpXVtR48ercx//vOfK3Opw1Fa71bqfDx48KAyN9tlLXWGSveDtL/Z21V1mBqGIXbIkv+bMmWKMpe6rKXuZakLWupqltZ8Hj58uDKPiIhQ5tJjRlorWxqnVGukx560trb0mJTW+j5z5oyp40ik8Us18bnnnjN1/NvBZ8pERESa4KRMRESkCU7KREREmuCkTEREpAnLJ+Xf/OY3CAoK6rFJS5cREQGsG0RXeaT7+gc/+AE+++yzv9+I0MFHfSN1aEodhQ8++KAyT0tLU+ZSh6PNZlPmUqfnP/3TPynz//iP/1Dm9fX1ylxav1Y6X8ngwYOVudRNfenSJVPHp9vjC3Vj9uzZylx6bEi59DsnPbbb29uV+QsvvKDMa2pqlLn02HY6ncq8trZWmUtd3B0dHcpcuh+kx+Q//uM/KvPly5crc7Nd7tL9/9Of/lSZ92f3tUd+6wcOHAiHw+GJQxORn2LdIPLQe8rHjx+H0+nEHXfcgccffxynT58W921vb0djY2OPjYgCj5m6AbB2kH+yfFJOSUlBQUEBCgsLsW7dOlRVVeGBBx4QLwbPy8uD3W53b4mJiVYPiYg0Z7ZuAKwd5J8sn5QzMjLwL//yL5g4cSLS09Px8ccfo6GhAX/5y1+U++fm5sLlcrm36upqq4dERJozWzcA1g7yTx7vpIiOjsbYsWNx4sQJ5fdtNpvYBEBEgelWdQNg7SD/5PFJubm5GZWVlXjiiSc8fVMBQ+pwlEydOlWZjxo1SplLHaBSx+Wnn36qzP/hH/5Bma9evVqZHzp0SJn/7W9/U+ZfffWVMp82bZoyl+6H/fv3K/OSkpIbMsMw+N5lP9C1bkjdudLay2avlJDWuHa5XMr83//935X53LlzlbnU1bxhwwZl/otf/EKZHz16VJnHxMQoc+l+kK64eOedd5T5s88+q8ylLmvp/pSurJAuwxs7dqwy/+abb5T57bD85evnnnsOxcXFOHnyJPbv34+HH34YAwYMwGOPPWb1TRGRn2DdILrC8mfKZ86cwWOPPYYLFy5g2LBhmDFjBkpLSzFs2DCrb4qI/ATrBtEVlk/KmzdvtvqQROTnWDeIruDa10RERJrgpExERKQJ/RaXJbegoCBlLq0FLa01fe+99ypzaWGGQYMGKXOpA1HK/+d//keZS5e5SOvgpqamKvOFCxcq887OTlPj+fnPf67MVesNX758GX/961+V+5P/mzRpkjKXrpGWrlgweylXVFSUqf0LCwuVeUtLizK/5557lLm05vO2bduU+fz585W51B395ZdfKvMpU6Yoc6nLXapZUpe7tPa1tIqcVIN8ovuaiIiI+oaTMhERkSY4KRMREWmCkzIREZEmOCkTERFpIsiQWnm9pLGxEXa73dvD8Aipm9os6b+stLRUmUtrXEukcUqdj2bX4m5ra1PmUkek1KEpdXFL45w3b54yv+OOO5T58OHDlTlwZS1isx2x5FlW1o7x48cr848//liZNzc3mzq+9BgLDw9X5hcuXFDmUpey1E2tuqIAABISEpS5tMa1NH7pygdpf6mr+b/+67+UeVFRkTKXHqvSeKQ8JCREmR84cECZS1du3MytagefKRMREWmCkzIREZEmOCkTERFpgpMyERGRJjgpExERaYJrX/cjTze6X7x4UZlLnZWtra3KXFqXV1q/VlqzWuqyljpMpe7rBx54QJnff//9ylxabzguLk6ZS+sEU+B64YUXlLn0uyt1X0trL0vHkR4z0hUF0rr2Q4cOVeYxMTHKXOo6jo+PV+ZS97I0/tDQUGUeHR2tzB955BFlPmTIEGUu1TKpG1/aXxqndD97Ap8pExERaYKTMhERkSY4KRMREWmCkzIREZEmTE/K+/btw/z58+F0OhEUFITt27f3+L5hGFi1ahUSEhIQHh6OtLQ0HD9+3KrxEpEPYt0g6h3T3dctLS2YNGkSnnzySSxcuPCG769evRpr167F+++/j+TkZLz88stIT0/HsWPHEBYWZsmgSS0iIkKZS93IUn7p0iVl7nK5lLm0Lq+05rbUhS6tjyuNUzpfqeNV6u5OTExU5mQdX6sb+/fvV+YOh0OZjx49WplLaxwPGjRImUt/iEi/09J699LvupRLxx8wYIAyl67EkB7D0vGlx3ZTU5My/+abb5S5VAuk8Uu3W1NTo8yv/yPSk0xPyhkZGcjIyFB+zzAMrFmzBi+99BIeeughAMDGjRsRHx+P7du349FHH7290RKRT2LdIOodS99TrqqqQl1dHdLS0tyZ3W5HSkoKSkpKlD/T3t6OxsbGHhsRBY6+1A2AtYP8k6WTcl1dHYAbLziPj493f+96eXl5sNvt7o0vJRIFlr7UDYC1g/yT17uvc3Nz4XK53Ft1dbW3h0REPoC1g/yRpZPy1SaI+vr6Hnl9fb3YIGGz2RAVFdVjI6LA0Ze6AbB2kH+ydO3r5ORkOBwOFBUVYfLkyQCAxsZGHDhwAMuWLbPypnyS2e5iqWNRWmva6XQq8/b2dlO5tPZ1R0eHMpe6taV1baVubamDUlqPVurQlNa7LS8vV+bS/ala77arqwuHDx9W7k99o2PdWLdunalcWpN5zJgxylw6rx/+8IfK/Pvvv1fmR48eVeYNDQ3KXFrjWupStorZ2ietoW32sf3444/3YnR6MT0pNzc348SJE+6vq6qqcOTIEcTExCApKQkrVqzAb3/7W4wZM8Z9aYPT6cSCBQusHDcR+RDWDaLeMT0pHzp0CLNnz3Z/nZOTAwBYvHgxCgoK8Pzzz6OlpQVLly5FQ0MDZsyYgcLCQl6jTBTAWDeIesf0pDxr1qybfgRhUFAQXnvtNbz22mu3NTAi8h+sG0S94/XuayIiIrqCkzIREZEmLO2+ppuTXr6TOh+l7utHHnlEmUuXj5w7d06Zh4eHK3NpfVxpvV5p0QapW1vq7u7s7FTm0jq70viHDh2qzPPz85X51Y7f3t4u0fUuXryozA8ePKjMpSsfHnzwQWUu1Q7pygTpsSrVGukxL5G6qaVcOr7ZKz2kHgNprXJfxGfKREREmuCkTEREpAlOykRERJrgpExERKQJTspERESaYHtpP5K6eaVOQ4m03q3U0Wl2vVup6zsuLk6ZS+vUSmtcS+OROiulTlKp4/XMmTPKfNGiRcr8rbfeUualpaXKnAKX1F0s/U5Lj22pm1r6TGizj9WbLdSiIp2X2eNYxexa3NJa32aPL3WJ9+f9wGfKREREmuCkTEREpAlOykRERJrgpExERKQJTspERESa8Ivua6lzUOqwCw5W/y0iHUdak9nserGXL182tb/k448/VuYtLS3KvLW1VZlL6+ZKnYbSGtrS/Sx1U0v3p8Ts/S+NZ+LEicrc5XKZGg8FLumxYfZ3urKyUplL3ddWXbkhjd+q7mvpOBJp/FI3u0S63yTSHCB1s/cnPlMmIiLSBCdlIiIiTXBSJiIi0gQnZSIiIk2YnpT37duH+fPnw+l0IigoCNu3b+/x/SVLliAoKKjHNm/ePKvGS0Q+iHWDqHdMd1+3tLRg0qRJePLJJ7Fw4ULlPvPmzcOGDRvcX9tstr6P8Bpm13+1qtvZKjNnzlTmmZmZynz69OnK/NKlS8pcWmta6rKWOjql+1O6Xen/Rfp/l7qypU5P6XYl0vk2Nzcrc+n3eOfOnaZul2TerBv9wWw3r3RFhNSNLN0XUo2THttmu6yl/aVcuh+k40vr9UdERJi6Xd1q/e0wPSlnZGQgIyPjpvvYbDY4HI4+D4qI/AvrBlHveOQ95b179yIuLg533XUXli1bJj6DA678pdTY2NhjI6LAY6ZuAKwd5J8sn5TnzZuHjRs3oqioCG+++SaKi4uRkZEhvoyTl5cHu93u3hITE60eEhFpzmzdAFg7yD9ZvqLXo48+6v73hAkTMHHiRNx5553Yu3cv5syZc8P+ubm5yMnJcX/d2NjIBxdRgDFbNwDWDvJPHr8k6o477kBsbCxOnDih/L7NZkNUVFSPjYgC263qBsDaQf7J42tfnzlzBhcuXEBCQsJtH8uqdUljYmKUudPpVOZjxowxtb/UXTp27FhlLnUgSp2MUjfy0KFDlXlNTY0yb2trU+ZS93JcXJwylzpGpQ7K/fv3K/PBgwcrc6lrXVr7WlrLWlqf+L777lPm5D1W1o3+YHaNaOl3V6px0vGlXKodZscjXVkhsaorWxqP2eNIzO7fn0xPys3NzT3+eq2qqsKRI0cQExODmJgYvPrqq8jMzITD4UBlZSWef/55jB49Gunp6ZYOnIh8B+sGUe+YnpQPHTqE2bNnu7+++p7O4sWLsW7dOpSXl+P9999HQ0MDnE4n5s6di9dff92nrjkkImuxbhD1julJedasWTd96v/pp5/e1oCIyP+wbhD1Dte+JiIi0gQnZSIiIk14vPvaSlKX7Ouvv67Mhw0bpsyjo6OVudT5KHUgNjQ0KHNpHdampiZlLnUvS52M0rq5Ulfzv/7rvyrzQ4cOKfPIyEhlLnWJjxo1SplLJkyYYOp2q6urlbnUhR4eHq7Mpe7ukSNHKnOi/jZ8+HBlfvHiRWUu1SazXdlSrfE0aTzSlRLSOM12ieuMz5SJiIg0wUmZiIhIE5yUiYiINMFJmYiISBOclImIiDShbfd1cHDwDZ12a9euVe4rrY8rdVNLudTNK5HWiJaOL3VNS+x2uzKXuoXfeOMNU7e7bNkyZW52reyioiJl/u233ypzaS1xae1uqTs9JCREmZvt6Dx37pwyJ+otq9ZSlq7ckJitQVL3stlcOl9pf2kta+kxLF3pId2udByJzmtf85kyERGRJjgpExERaYKTMhERkSY4KRMREWmCkzIREZEmtO2+fuyxx27oLJS6jisrK5W5tNaxlMfExJgYodzxJ3VNS2s4S93OERERyry+vl6Zv//++8p8wYIFynznzp3KXFrLWrrfpkyZosyv/fzca0nd0VKXtfSZulLnqUTqSJX+HxMTE2/Iuru78d1335m6XaLekrqOpbWdpW5taX+pC1rqRpaOIz1WpeMMHKieaqT9zV4JI32egS/iM2UiIiJNcFImIiLSBCdlIiIiTXBSJiIi0oSpSTkvLw9Tp05FZGQk4uLisGDBAlRUVPTYp62tDVlZWRg6dCgGDx6MzMxMsTGJiAIDawdR75jqvi4uLkZWVhamTp2Ky5cv49e//jXmzp2LY8eOYdCgQQCAlStX4qOPPsKWLVtgt9uRnZ2NhQsX4r//+79NDezcuXM3dMVK3cuRkZHKXOpklI4jdRdLXb5RUVHK/Pvvv1fmp06dMnW70prV0hrUUifmtm3blPnf/vY3ZS51X0vd6VInZkNDgzKX1qCWxm923Vxpf2ldXun/d+zYsTdkly9fZvd1H/Rn7fBl0u+uWWbXrJZIV0pIx5eYXStb2l+qEeHh4ZaMRwemJuXCwsIeXxcUFCAuLg5lZWWYOXMmXC4X/vjHP2LTpk148MEHAQAbNmzA3XffjdLSUtx3333WjZyIfAZrB1Hv3NZ7yi6XC8Dfn0GVlZWhs7MTaWlp7n3GjRuHpKQklJSUKI/R3t6OxsbGHhsR+TfWDiK1Pk/K3d3dWLFiBaZPn47x48cDAOrq6hAaGnrDhdzx8fGoq6tTHicvLw92u929qRZsICL/wdpBJOvzpJyVlYWjR49i8+bNtzWA3NxcuFwu9ya930tE/oG1g0jWp2U2s7OzsWvXLuzbtw8jRoxw5w6HAx0dHWhoaOjxF299fT0cDofyWDabTVxGkYj8C2sH0c2ZmpQNw8Dy5cuxbds27N27F8nJyT2+P2XKFISEhKCoqAiZmZkAgIqKCpw+fRqpqammBlZbW3vDuqtSx9yZM2eU+dWuzuvFxsYqc6lb+Pz588r83Llzylxa51UqIFIXcVhYmDKXus2lTklp/Hfffbcyb2lpUebSM5GLFy8qc+l8pfGY7cqW9pc6MaXifvX9zetNnjz5hqy9vR3FxcXK/UnWn7XDl0mPYbOs6i72dPe1dHyz3dfS5wT4IlOTclZWFjZt2oQdO3YgMjLS/V6P3W5HeHg47HY7nnrqKeTk5CAmJgZRUVFYvnw5UlNT2T1JFMBYO4h6x9SkvG7dOgDArFmzeuQbNmzAkiVLAADvvPMOgoODkZmZifb2dqSnp+MPf/iDJYMlIt/E2kHUO6Zfvr6VsLAw5OfnIz8/v8+DIiL/wtpB1Dtc+5qIiEgTnJSJiIg00adLovqDal3mrVu3Kvd98sknlXlNTY0y//bbb5W5tKa0tDa11DUtdf9Kayxf32V+lbR2d1dXlzKXXiK8dOmSMq+trTV1HOl2pW5zs/en2TW0rVpb+/pO4KtUH4YgjZECm6fXUpZqhFlm16CWmB2PVWtuSzXIqvtHB3ymTEREpAlOykRERJrgpExERKQJTspERESa4KRMRESkCW27r1Xy8vKU+ZEjR5T5c889p8xHjRqlzKU1maUuX2mNaKkTUOq+lrqXpeNInZJSh6PUJS7l0jil/c12bkr7q7qdAblb++pn8V6vu7tbmUtrX5eXlyvz//zP/1TmRNcz+5iUSN39Vq3tLD02pFojXbFg1fmaZVX3tafHeTv4TJmIiEgTnJSJiIg0wUmZiIhIE5yUiYiINMFJmYiISBPadl8HBQXd0OEndQ5+8sknpvLZs2crc6m7e+TIkcrcbrcrc2ndVqlDUOq+ljoNJWfPnlXmUqfhd999p8ylNbebm5uVuVWdj9Ka1dLa3dL9vHv3bmX+1VdfKfP9+/crcyJdmF0LWuqOlo5jNpdqsdkrMaRaIN2uhGtfExERkeU4KRMREWmCkzIREZEmOCkTERFpwtSknJeXh6lTpyIyMhJxcXFYsGABKioqeuwza9Ysd5PW1e2ZZ56xdNBE5FtYO4h6x1T3dXFxMbKysjB16lRcvnwZv/71rzF37lwcO3YMgwYNcu/39NNP47XXXnN/3Zd1Ww3D8Nj6pHv27FHm9913n6njjBs3TpnHxsYqc2kN7REjRijzkydPKnOpS7myslKZE3lbf9YOb7CqVtXU1CjzsWPHKnNpbWqpO1rKpXXtzR5Huh+kLnHpyhOJdHx/Wvva1D1SWFjY4+uCggLExcWhrKwMM2fOdOcRERHi4v9EFHhYO4h657beU3a5XABu/LSeP//5z4iNjcX48eORm5srXmcKXLkmtrGxscdGRP6NtYNIrc+Lh3R3d2PFihWYPn06xo8f784XLVqEkSNHwul0ory8HC+88AIqKiqwdetW5XHy8vLw6quv9nUYRORjWDuIZH2elLOysnD06FF88cUXPfKlS5e6/z1hwgQkJCRgzpw5qKysxJ133nnDcXJzc5GTk+P+urGxEYmJiX0dFhFpjrWDSNanSTk7Oxu7du3Cvn37xCalq1JSUgAAJ06cUD6wbDYbbDZbX4ZBRD6GtYPo5kxNyoZhYPny5di2bRv27t2L5OTkW/7MkSNHAAAJCQl9GqDOvv76a0uOc/ToUUuOQ6Qr1o7eiY6OVubXdqhfS+pelq4AMbvGtdSVbZbUfS11TVdXVytzqRtf9UfbzZhd07s/mZqUs7KysGnTJuzYsQORkZGoq6sDcOWDGcLDw1FZWYlNmzbhRz/6EYYOHYry8nKsXLkSM2fOxMSJEz1yAkSkP9YOot4xNSmvW7cOwJWL/K+1YcMGLFmyBKGhofjss8+wZs0atLS0IDExEZmZmXjppZcsGzAR+R7WDqLeMf3y9c0kJiaiuLj4tgZERP6HtYOod7j2NRERkSY4KRMREWmiz9cpExHRFUFBQcrc7BrLhw8fVubHjh1T5tJ6+ma7pqVu5ObmZmUunZd0P5hdo7ujo0OZDxkyRJkfPHhQmUt06LKW8JkyERGRJjgpExERaYKTMhERkSY4KRMREWlCu0YvnT98mugq/p7qx5v/J1bddltbmzKXGpOk/aVlLSVSo1d7e7sy91ajl3S+nZ2dylxHt/pd0W5Sbmpq8vYQiG6pqakJdrvd28Oga/hD7Xj55Ze9PQTysFvVjiBDsz/5u7u7UVNTg8jISDQ1NSExMRHV1dWIiory9tA87upHz/F89WUYBpqamuB0OsVnF+QdrB08X531tnZo90w5ODjY/ZFuV18KiYqK8pk73go8X73xGbKeWDt4vrrrTe3gn/pERESa4KRMRESkCa0nZZvNhldeeQU2m83bQ+kXPF8iawTa7xbP139o1+hFREQUqLR+pkxERBRIOCkTERFpgpMyERGRJjgpExERaULrSTk/Px+jRo1CWFgYUlJSTH+Qta727duH+fPnw+l0IigoCNu3b+/xfcMwsGrVKiQkJCA8PBxpaWk4fvy4dwZrgby8PEydOhWRkZGIi4vDggULUFFR0WOftrY2ZGVlYejQoRg8eDAyMzNRX1/vpRGTL/PXugEEVu0I1Lqh7aT84YcfIicnB6+88gq+/PJLTJo0Cenp6Th79qy3h3bbWlpaMGnSJOTn5yu/v3r1aqxduxbr16/HgQMHMGjQIKSnp4uLseuuuLgYWVlZKC0txe7du9HZ2Ym5c+eipaXFvc/KlSuxc+dObNmyBcXFxaipqcHChQu9OGryRf5cN4DAqh0BWzcMTU2bNs3Iyspyf93V1WU4nU4jLy/Pi6OyHgBj27Zt7q+7u7sNh8NhvPXWW+6soaHBsNlsxgcffOCFEVrv7NmzBgCjuLjYMIwr5xcSEmJs2bLFvc9XX31lADBKSkq8NUzyQYFSNwwj8GpHoNQNLZ8pd3R0oKysDGlpae4sODgYaWlpKCkp8eLIPK+qqgp1dXU9zt1utyMlJcVvzt3lcgEAYmJiAABlZWXo7Ozscc7jxo1DUlKS35wzeV4g1w3A/2tHoNQNLSfl8+fPo6urC/Hx8T3y+Ph41NXVeWlU/ePq+fnruXd3d2PFihWYPn06xo8fD+DKOYeGhiI6OrrHvv5yztQ/ArluAP5dOwKpbmj3KVHk37KysnD06FF88cUX3h4KEfmIQKobWj5Tjo2NxYABA27ooquvr4fD4fDSqPrH1fPzx3PPzs7Grl27sGfPHvdH7AFXzrmjowMNDQ099veHc6b+E8h1A/Df2hFodUPLSTk0NBRTpkxBUVGRO+vu7kZRURFSU1O9ODLPS05OhsPh6HHujY2NOHDggM+eu2EYyM7OxrZt2/D5558jOTm5x/enTJmCkJCQHudcUVGB06dP++w5U/8L5LoB+F/tCNi64e1OM8nmzZsNm81mFBQUGMeOHTOWLl1qREdHG3V1dd4e2m1ramoyDh8+bBw+fNgAYLz99tvG4cOHjVOnThmGYRhvvPGGER0dbezYscMoLy83HnroISM5OdlobW318sj7ZtmyZYbdbjf27t1r1NbWurdLly6593nmmWeMpKQk4/PPPzcOHTpkpKamGqmpqV4cNfkif64bhhFYtSNQ64a2k7JhGMa7775rJCUlGaGhoca0adOM0tJSbw/JEnv27DEA3LAtXrzYMIwrlza8/PLLRnx8vGGz2Yw5c+YYFRUV3h30bVCdKwBjw4YN7n1aW1uNZ5991hgyZIgRERFhPPzww0Ztba33Bk0+y1/rhmEEVu0I1LrBj24kIiLShJbvKRMREQUiTspERESa4KRMRESkCU7KREREmuCkTEREpAlOykRERJrgpExERKQJTspERESa4KRMRESkCU7KREREmtDu85S7u7tRU1ODyMhIBAUFeXs4RD0YhoGmpiY4nU4EB/NvWp2wdpDOel07PLWo9nvvvWeMHDnSsNlsxrRp04wDBw706ueqq6vFhci5cdNlq66u9tRDJ6D1tW4YBmsHN9/YblU7PPJM+cMPP0ROTg7Wr1+PlJQUrFmzBunp6aioqEBcXNxNfzYyMtITQ9JCbGysMn/88ceV+QcffKDMz549a9mYzJowYYIyHzt2rDLfsWOHMr98+bJlY/IGf/499ZbbqRuAf/yfJCUlKfMZM2Yo8x//+MfK/Pvvv1fmH374oTL/3//9X2UuPa5/8pOfKPMf/vCHyry1tdXUeAoKCpS5P7jV76lHJuW3334bTz/9NH72s58BANavX4+PPvoIf/rTn/Diiy/22Le9vR3t7e3ur5uamjwxJC1IL1nYbDZT+3vTgAEDlHlISIgy99eXEf31vLzJTN0A/LN2SI/50NBQZR4REaHMpUlw4EB1yZd+n6XHe1hYmDIfPHiwMjd7Xv7sVrXD8qrf0dGBsrIypKWl/f1GgoORlpaGkpKSG/bPy8uD3W53b4mJiVYPiYg0Z7ZuAKwd5J8sn5TPnz+Prq4uxMfH98jj4+NRV1d3w/65ublwuVzurbq62uohEZHmzNYNgLWD/JPXu69tNpv48i0RkYS1g/yR5ZNybGwsBgwYgPr6+h55fX09HA6H1TenJel9Fak54oknnlDmjzzyiDI/f/68Mu/o6DCVA3LTgVTsRowYocylhq6uri5lvmXLFnFMFHj8tW5kZGQo85UrVypz6b1g6b3XtrY2ZT5q1ChlvnnzZmV+/SsUV508eVKZS42atbW1ytzlcinzn/70p8r8l7/8pTIvKipS5v/2b/+mzH2R5S9fh4aGYsqUKT3uvO7ubhQVFSE1NdXqmyMiP8C6QXSFR16+zsnJweLFi3Hvvfdi2rRpWLNmDVpaWtxdlURE12PdIPLQpPzII4/g3LlzWLVqFerq6jB58mQUFhaKL5EQEbFuEHmw0Ss7OxvZ2dmeOjwR+SHWDQp0+q1OQUREFKC8fkmUP2publbmUgdibm6uMv9//+//KfNx48Ypc+llvptdNnLx4kVlLp3D7t27lfnHH3+szKVOdCJ/cueddyrzRYsWKfPy8nJlLq3QJa2I1d3drcyla7bNrnomHV/KpRondWt3dnYqc2nBmOHDhyvz3//+98r8ueeeU+Y64zNlIiIiTXBSJiIi0gQnZSIiIk1wUiYiItIEJ2UiIiJNsPu6H0nr1zY0NCjz9957T5lL67xe+9my17pZ97V022VlZcp8w4YNyjw5OVmZnzt3TrxtIn/xq1/9Spmb/f2Xuqylzy+WupqlvKqqSplLXdPS7Urd12Y/IERaG1/63OdTp04p8/HjxyvzH//4x8r8o48+6sXovIPPlImIiDTBSZmIiEgTnJSJiIg0wUmZiIhIE5yUiYiINMHu634krScdGxurzKVOw5ycHGU+YsQIZT5s2DBxTFI35oULF5S5NFapWzIoKEi8bSJ/UVBQoMxXrlypzKWu7Pr6emUeGRmpzKW1oyUdHR3KXHpcSxobG5V5a2urqeNIpHHa7XZlLq31rXOXtYTPlImIiDTBSZmIiEgTnJSJiIg0wUmZiIhIE5yUiYiINGF59/VvfvMbvPrqqz2yu+66C19//bXVN+VzpPVoJWY7Is+fP6/M6+rqxJ+JiIhQ5sOHD1fm0lq1hmGYyomu5et14+DBg8q8pKREmf/kJz9R5gcOHFDm0tUN0uNXunpC6mqWakdbW5up25XGKXVr3+zKEDO3++KLL5o6js48cknUD37wA3z22Wd/vxHhP4qI6CrWDSIPTcoDBw6Ew+Ho1b7t7e09Pt1I+ouKiPybmboBsHaQf/LIe8rHjx+H0+nEHXfcgccffxynT58W983Ly4PdbndviYmJnhgSEWnOTN0AWDvIP1k+KaekpKCgoACFhYVYt24dqqqq8MADD6CpqUm5f25uLlwul3uTVmYhIv9ltm4ArB3knyx/+TojI8P974kTJyIlJQUjR47EX/7yFzz11FM37G+z2Ux/MDYR+RezdQNg7SD/5PFOiujoaIwdOxYnTpzw9E1pLzhY/cKE1KEsdToPGDBAmUdHR/dpXGZIa1lL58BmHeoLf6kba9euVea//OUvlbn0kr20VnZLS4syv3TpkjK/2SsPKlKtkW5XeryHhISYGo+0xvUnn3yizP2pn8Dj1yk3NzejsrISCQkJnr4pIvITrBsUqCyflJ977jkUFxfj5MmT2L9/Px5++GEMGDAAjz32mNU3RUR+gnWD6ArLX1s8c+YMHnvsMVy4cAHDhg3DjBkzUFpaavoicSIKHKwbRFdYPilv3rzZ6kMSkZ9j3SC6gmtfExERaYKtsf1o8ODByly6rENad1bqiOzu7ja1PyB3U0ukDnIpDwsLM3V8Il8kdR1L693PmDFDmf/ud78zdbtSl7V0u+Hh4cq8tbVVmUvnJeXXrrB2Lak+SKT9d+7caeo4vojPlImIiDTBSZmIiEgTnJSJiIg0wUmZiIhIE5yUiYiINMHu634kdSxKHdBSLnUmmj1OX44ldXVKx7lZ5zeRv5AeF5La2lplXllZqcyTk5OVuXSFhrSmtHSFhnQc6XHd3NyszKXFXszWjVOnTinzQMBnykRERJrgpExERKQJTspERESa4KRMRESkCU7KREREmmD3dT+SOg2l9WulzmWzHdNdXV29GF1PhmGY2l9a85aIek96bEdGRipzqZtaWk+/sbFRmYeGhipzqSu7o6NDmUvMdqefPXvW1P7+hM+UiYiINMFJmYiISBOclImIiDTBSZmIiEgTnJSJiIg0YXpS3rdvH+bPnw+n04mgoCBs3769x/cNw8CqVauQkJCA8PBwpKWl4fjx41aN16cFBwcrN8mAAQOUW3d3t3Ize7s3u23JwIEDlVt7e7tyi42NVW4UWAK1bph93J05c0a53ewxrNqkx6NhGMotJCREuQUFBSm3sLAw5dba2mpqk+rJd999p9wk0nF8kemq3NLSgkmTJiE/P1/5/dWrV2Pt2rVYv349Dhw4gEGDBiE9PV1srSci/8e6QdQ7pv+UyMjIQEZGhvJ7hmFgzZo1eOmll/DQQw8BADZu3Ij4+Hhs374djz766A0/c/UvuKuk6+iIyHdZXTcA1g7yT5a+p1xVVYW6ujqkpaW5M7vdjpSUFJSUlCh/Ji8vD3a73b0lJiZaOSQi0lxf6gbA2kH+ydJJua6uDgAQHx/fI4+Pj3d/73q5ublwuVzurbq62sohEZHm+lI3ANYO8k9efyfcZrOJS8IREUlYO8gfWTopOxwOAEB9fT0SEhLceX19PSZPnmzlTWltyJAhylxay1pas1paf7ovXdNmSd3cUkej1JAzaNAgZR4WFmbqOOS/WDf+7uTJk8pcesxLa1ZLNUg6vrQ29dChQ5X5xYsXTR1HWhtfOi+za2X7E0ure3JyMhwOB4qKitxZY2MjDhw4gNTUVCtvioj8BOsG0d+Zfqbc3NyMEydOuL+uqqrCkSNHEBMTg6SkJKxYsQK//e1vMWbMGCQnJ+Pll1+G0+nEggULrBw3EfkQ1g2i3jE9KR86dAizZ892f52TkwMAWLx4MQoKCvD888+jpaUFS5cuRUNDA2bMmIHCwkLx5Uoi8n+sG0S9Y3pSnjVr1k0/azcoKAivvfYaXnvttdsaGBH5D9YNot7h2tdERESa8PolUf5I6jSU8ps9gzCjL8eROr/NdnhLneUul0uZs8ua6Eatra3K/GZr25vZX3qcSm8TSMeRuq+lde0jIyOVuSQkJMTU/v6Ez5SJiIg0wUmZiIhIE5yUiYiINMFJmYiISBOclImIiDTB7msPkLqgpc5HXyKdGz8YgOhGZrumpTWfz507p8w7OjqUudQdLZH2l44fHh6uzM+ePavMhw0bpsybm5t7MbrAwmfKREREmuCkTEREpAlOykRERJrgpExERKQJTspERESaYPe1B5jtspY6NM2uP232+FbehnScrq4uU/ub7VYl0pnZ33NpjeghQ4Yo80uXLinzmJiYXozu786fP6/MIyIilLndblfmUre2RFp7f+TIkaaOI3Wt+yI+UyYiItIEJ2UiIiJNcFImIiLSBCdlIiIiTXBSJiIi0oTp7ut9+/bhrbfeQllZGWpra7Ft2zYsWLDA/f0lS5bg/fff7/Ez6enpKCwsvO3B+oqwsDBlLq0bLeVSZ6LZjmYr19yWxmT23EJDQ5V5W1tb3wZGWgvUumH2agJpjeujR48q8+rqamUudU1Lj6/4+HhlLnVTnzx50tTxpW7t2tpaZe50OpV5IDD9TLmlpQWTJk1Cfn6+uM+8efNQW1vr3j744IPbGiQR+TbWDaLeMf1MOSMjAxkZGTfdx2azweFw9Op47e3taG9vd3/d2NhodkhEpDmr6wbA2kH+ySPvKe/duxdxcXG46667sGzZMly4cEHcNy8vD3a73b0lJiZ6YkhEpDkzdQNg7SD/ZPmkPG/ePGzcuBFFRUV48803UVxcjIyMDPF90NzcXLhcLvcmvUdCRP7LbN0AWDvIP1m+zOajjz7q/veECRMwceJE3Hnnndi7dy/mzJlzw/42mw02m83qYRCRDzFbNwDWDvJPHl/7+o477kBsbCxOnDghPrj8jdShbDaXOpfN3m5/MHvbVq25Tf4pEOsGADzwwAPK/Ntvv1Xmp06dUuZSF7T0vntUVJQyl7qmW1tblbnUrZ2QkKDMJVJvQVxcnDI/e/asMvfFNfY9XhnPnDmDCxcumP5PIaLAxbpBgcr0M+Xm5macOHHC/XVVVRWOHDmCmJgYxMTE4NVXX0VmZiYcDgcqKyvx/PPPY/To0UhPT7d04ETkO1g3iHrH9KR86NAhzJ492/11Tk4OAGDx4sVYt24dysvL8f7776OhoQFOpxNz587F66+/zvd+iAIY6wZR75ielGfNmnXT9zo//fTT2xoQEfkf1g2i3mG3DRERkSY83n0diKxca9oMs2to34zZjnDpnKV84ED+6pH/MNvlKy10cs899yhzqfs6OjpamcfGxirza9/Xv9agQYOUeXJysjJvaGhQ5lIXt1nNzc3KfNGiRcp8zZo1ylznLmsJnykTERFpgpMyERGRJjgpExERaYKTMhERkSY4KRMREWmCLbAeIHUuS594Y7Zr2uy60WbX0L7Zz5i9bekcpDV1+Zm45IvMdvlKK5UdO3ZMmYeFhSlz6fEyatQoZf7dd98p83Hjxilz6bzOnDmjzCdOnKjM6+vrlfnQoUOV+cWLF5X58OHDlfno0aOVudRtrjM+UyYiItIEJ2UiIiJNcFImIiLSBCdlIiIiTXBSJiIi0gS7rz0gJCREmUudy2bXpja7LnV/MNtZzo/ko0AmdSmXl5crc2kN+dDQUGVu9vFldr1+qStbytva2pS5tAa41FVuttuc3ddERETUZ5yUiYiINMFJmYiISBOclImIiDTBSZmIiEgTprqv8/LysHXrVnz99dcIDw/H/fffjzfffBN33XWXe5+2tjb86le/wubNm9He3o709HT84Q9/QHx8vOWD19XAgeq7VeqaljofvdlNLbl8+bKp/Ts7O5W52TW0ybcFau2QuoJra2uVubTGdXNzszKXao30OA0PD1fmEuk4Upe12a7vS5cuKXPp/1xau3vYsGGmbldnpipjcXExsrKyUFpait27d6OzsxNz585FS0uLe5+VK1di586d2LJlC4qLi1FTU4OFCxdaPnAi8h2sHUS9Y+qZcmFhYY+vCwoKEBcXh7KyMsycORMulwt//OMfsWnTJjz44IMAgA0bNuDuu+9GaWkp7rvvvhuO2d7ejvb2dvfX/JQgIv/D2kHUO7f1GqLL5QIAxMTEAADKysrQ2dmJtLQ09z7jxo1DUlISSkpKlMfIy8uD3W53b9LF5ETkP1g7iNT6PCl3d3djxYoVmD59OsaPHw8AqKurQ2hoKKKjo3vsGx8fj7q6OuVxcnNz4XK53Ft1dXVfh0REPoC1g0jW52U2s7KycPToUXzxxRe3NQCbzcYlF4kCCGsHkaxPk3J2djZ27dqFffv2YcSIEe7c4XCgo6MDDQ0NPf7ira+vh8PhuO3B+gppPVqJ1GUtdTjq2LksnYPUfR0REeHJ4ZCmAq12JCUlKXPpsS11U0s1RerWltail44vGTJkiDKXurKl40t5VVWVMh8zZowyr6+vV+Z2u12ZX3175Hrff/+9MteBqepuGAays7Oxbds2fP7550hOTu7x/SlTpiAkJARFRUXurKKiAqdPn0Zqaqo1IyYin8PaQdQ7pv5sysrKwqZNm7Bjxw5ERka63+ux2+0IDw+H3W7HU089hZycHMTExCAqKgrLly9HamqqsnuSiAIDawdR75ialNetWwcAmDVrVo98w4YNWLJkCQDgnXfeQXBwMDIzM3ssAEBEgYu1g6h3TE3KvVlhKiwsDPn5+cjPz+/zoIjIv7B2EPWOfh1DREREAarPl0SRTOqUlJ4tSJ2M0lrZ3iR1fkvdnlL39ejRo5X5kSNH+jQuIh1J69pLjyNpLWjpaoWQkBBl3tHRocylrm+pNg0ePFiZSzXr2hXWrjV8+HBlfujQIWU+c+ZMZS6tGS51d0vd437TfU1ERESew0mZiIhIE5yUiYiINMFJmYiISBOclImIiDTB7msPcDqdpvaXOjHNroktdXr25hrR3o5Jum2pU1zq0jx//rzpMRH5mtjYWGUuXaFx7tw5ZX7107SuJ619LX22tHS70uM0MjLS1HHa2tqU+cSJE5X5Rx99pMwbGhpM3a7UZW12rW8d8JkyERGRJjgpExERaYKTMhERkSY4KRMREWmCkzIREZEmfK81zQdIHYjSOrVSd7TUTS11OkvrT0vHuRlpzWrpWFJXtrR27qlTp0yPicjXSN3X0tUNFy5cUOZ2u12ZS93F0hrRUvfyxYsXlXlLS4syl8ZvVnNzs6nxSHVGGmdCQoIyr6io6MXovIPPlImIiDTBSZmIiEgTnJSJiIg0wUmZiIhIE5yUiYiINGGq+zovLw9bt27F119/jfDwcNx///148803cdddd7n3mTVrFoqLi3v83C9+8QusX7/emhH7gIMHDyrzsWPHKvPo6Ghl3traaup2za4/DfRtXWwVqctR6gj/5ptvLLld8g2BWjukqw8uXbqkzKU1nCXS2tcdHR3KXOrWHjZsmDKX1uIeNGiQqeNIXeh33nmnMpe6rM2uyS+t3a0zU8+Ui4uLkZWVhdLSUuzevRudnZ2YO3fuDe3oTz/9NGpra93b6tWrLR00EfkW1g6i3jH1TLmwsLDH1wUFBYiLi0NZWRlmzpzpziMiIuBwOHp1zPb2drS3t7u/lj7dhIh8F2sHUe/c1nvKLpcLABATE9Mj//Of/4zY2FiMHz8eubm54ks1wJWXtex2u3tLTEy8nSERkQ9g7SBS6/OKXt3d3VixYgWmT5/e47M+Fy1ahJEjR8LpdKK8vBwvvPACKioqsHXrVuVxcnNzkZOT4/66sbGRDy4iP8baQSTr86SclZWFo0eP4osvvuiRL1261P3vCRMmICEhAXPmzEFlZaXyTX2bzQabzdbXYRCRj2HtIJL1aVLOzs7Grl27sG/fPowYMeKm+6akpAAATpw4IXba+RvpJbeNGzcq89mzZytzqWNR6nyU1qW+Wfe1ROpylLqpq6qqlPmePXuU+c1eliT/FWi1Y8yYMcpcerxI3dQS6XEaERGhzKV1+ffv36/MFy1apMylLu6ioiJlLo1TyqUrUqQ1rs3WH52ZmpQNw8Dy5cuxbds27N27F8nJybf8mSNHjgCQL5khIv/H2kHUO6Ym5aysLGzatAk7duxAZGQk6urqAFz5BJPw8HBUVlZi06ZN+NGPfoShQ4eivLwcK1euxMyZMzFx4kSPnAAR6Y+1g6h3TE3K69atA3DlIv9rbdiwAUuWLEFoaCg+++wzrFmzBi0tLUhMTERmZiZeeuklywZMRL6HtYOod0y/fH0ziYmJN6zIQ0TE2kHUO1z7moiISBNBhlWLH1uksbERdrvd28O4LdIa1Fbd1dcvuHCVtBJSVFSU6du4+p5fb3Opq1Pi6fvI01wuV5/uV/IcHWuH1KUsXRFhdm1nqSv91KlTylzqeD958qQyJ+vdqnbwmTIREZEmOCkTERFpgpMyERGRJjgpExERaaLPa197iq80+tyMp89BOr60BGZfltmUGkusOjdf/3/29fH7Ix3/T8yOyez+Zh+n0v7Uf271f6zdpNzU1OTtIWjv4sWLpnKyXlNTk3advoFOx9oh/aEsMTspS2s+S06fPm1qf7LerWqHdpdEdXd3o6amBpGRkWhqakJiYiKqq6sD4vKTqx89x/PVl2EYaGpqgtPpFC9fIe9g7eD56qy3tUO7Z8rBwcHua+muXssaFRXlM3e8FXi+euMzZD2xdvB8ddeb2sE/9YmIiDTBSZmIiEgTWk/KNpsNr7zyCmw2m7eH0i94vkTWCLTfLZ6v/9Cu0YuIiChQaf1MmYiIKJBwUiYiItIEJ2UiIiJNcFImIiLSBCdlIiIiTWg9Kefn52PUqFEICwtDSkoKDh486O0hWWLfvn2YP38+nE4ngoKCsH379h7fNwwDq1atQkJCAsLDw5GWlobjx497Z7AWyMvLw9SpUxEZGYm4uDgsWLAAFRUVPfZpa2tDVlYWhg4disGDByMzMxP19fVeGjH5Mn+tG0Bg1Y5ArRvaTsoffvghcnJy8Morr+DLL7/EpEmTkJ6ejrNnz3p7aLetpaUFkyZNQn5+vvL7q1evxtq1a7F+/XocOHAAgwYNQnp6Otra2vp5pNYoLi5GVlYWSktLsXv3bnR2dmLu3LloaWlx77Ny5Urs3LkTW7ZsQXFxMWpqarBw4UIvjpp8kT/XDSCwakfA1g1DU9OmTTOysrLcX3d1dRlOp9PIy8vz4qisB8DYtm2b++vu7m7D4XAYb731ljtraGgwbDab8cEHH3hhhNY7e/asAcAoLi42DOPK+YWEhBhbtmxx7/PVV18ZAIySkhJvDZN8UKDUDcMIvNoRKHVDy2fKHR0dKCsrQ1pamjsLDg5GWloaSkpKvDgyz6uqqkJdXV2Pc7fb7UhJSfGbc3e5XACAmJgYAEBZWRk6Ozt7nPO4ceOQlJTkN+dMnhfIdQPw/9oRKHVDy0n5/Pnz6OrqQnx8fI88Pj4edXV1XhpV/7h6fv567t3d3VixYgWmT5+O8ePHA7hyzqGhoYiOju6xr7+cM/WPQK4bgH/XjkCqG9p9dCP5t6ysLBw9ehRffPGFt4dCRD4ikOqGls+UY2NjMWDAgBu66Orr6+FwOLw0qv5x9fz88dyzs7Oxa9cu7Nmzx/25t8CVc+7o6EBDQ0OP/f3hnKn/BHLdAPy3dgRa3dByUg4NDcWUKVNQVFTkzrq7u1FUVITU1FQvjszzkpOT4XA4epx7Y2MjDhw44LPnbhgGsrOzsW3bNnz++edITk7u8f0pU6YgJCSkxzlXVFTg9OnTPnvO1P8CuW4A/lc7ArZueLvTTLJ582bDZrMZBQUFxrFjx4ylS5ca0dHRRl1dnbeHdtuampqMw4cPG4cPHzYAGG+//bZx+PBh49SpU4ZhGMYbb7xhREdHGzt27DDKy8uNhx56yEhOTjZaW1u9PPK+WbZsmWG32429e/catbW17u3SpUvufZ555hkjKSnJ+Pzzz41Dhw4ZqampRmpqqhdHTb7In+uGYQRW7QjUuqHtpGwYhvHuu+8aSUlJRmhoqDFt2jSjtLTU20OyxJ49ewwAN2yLFy82DOPKpQ0vv/yyER8fb9hsNmPOnDlGRUWFdwd9G1TnCsDYsGGDe5/W1lbj2WefNYYMGWJEREQYDz/8sFFbW+u9QZPP8te6YRiBVTsCtW7w85SJiIg0oeV7ykRERIGIkzIREZEmOCkTERFpgpMyERGRJjgpExERaYKTMhERkSY4KRMREWmCkzIREZEmOCkTERFpgpMyERGRJjgpExERaeL/A5xSqXJGQl4wAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "x_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# one hot encode outputs (0000000001, 0000000010, 0000000100 ...)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "BtUTv07HRzNY"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = y_test.shape[1]\n",
        "\n",
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvbposjwR8Rm",
        "outputId": "2eb5d238-10cc-4152-d44c-6a10c5ab9f66"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 12s - 40ms/step - accuracy: 0.8220 - loss: 0.5096 - val_accuracy: 0.8464 - val_loss: 0.4330\n",
            "Epoch 2/10\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.8684 - loss: 0.3700 - val_accuracy: 0.8615 - val_loss: 0.3858\n",
            "Epoch 3/10\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.8817 - loss: 0.3306 - val_accuracy: 0.8697 - val_loss: 0.3627\n",
            "Epoch 4/10\n",
            "300/300 - 4s - 15ms/step - accuracy: 0.8907 - loss: 0.3031 - val_accuracy: 0.8762 - val_loss: 0.3538\n",
            "Epoch 5/10\n",
            "300/300 - 6s - 22ms/step - accuracy: 0.8958 - loss: 0.2850 - val_accuracy: 0.8772 - val_loss: 0.3393\n",
            "Epoch 6/10\n",
            "300/300 - 9s - 29ms/step - accuracy: 0.9017 - loss: 0.2682 - val_accuracy: 0.8837 - val_loss: 0.3281\n",
            "Epoch 7/10\n",
            "300/300 - 6s - 19ms/step - accuracy: 0.9066 - loss: 0.2552 - val_accuracy: 0.8738 - val_loss: 0.3421\n",
            "Epoch 8/10\n",
            "300/300 - 4s - 15ms/step - accuracy: 0.9105 - loss: 0.2431 - val_accuracy: 0.8831 - val_loss: 0.3255\n",
            "Epoch 9/10\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.9140 - loss: 0.2316 - val_accuracy: 0.8823 - val_loss: 0.3321\n",
            "Epoch 10/10\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.9183 - loss: 0.2220 - val_accuracy: 0.8847 - val_loss: 0.3268\n",
            "Baseline Error: 11.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the default parameters from hw3 the baseline error is much higher than in hw1. 11.53% compared to 1.82% Therefore the parameters given for MNIST are not ideal for fashion_MNIST. This could be because fashion MNIST dataset is more complex since clothing has more variance in each class than digit classes. However the following models will still be tested from hw1 to see how the changes effect the relative error even though it will still be high and then changes will be made to make a more accurate model."
      ],
      "metadata": {
        "id": "wqBTX5YRmhc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='leaky_relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "BV-VFAlySE8k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db6a7be-10c2-4d39-b3a0-520741e4096e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.5746 - loss: 1.4553 - val_accuracy: 0.6597 - val_loss: 1.1061\n",
            "Epoch 2/10\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.6898 - loss: 0.9787 - val_accuracy: 0.7078 - val_loss: 0.9058\n",
            "Epoch 3/10\n",
            "300/300 - 9s - 30ms/step - accuracy: 0.7290 - loss: 0.8437 - val_accuracy: 0.7330 - val_loss: 0.8164\n",
            "Epoch 4/10\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.7530 - loss: 0.7724 - val_accuracy: 0.7487 - val_loss: 0.7614\n",
            "Epoch 5/10\n",
            "300/300 - 9s - 31ms/step - accuracy: 0.7687 - loss: 0.7256 - val_accuracy: 0.7626 - val_loss: 0.7233\n",
            "Epoch 6/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.7790 - loss: 0.6915 - val_accuracy: 0.7723 - val_loss: 0.6948\n",
            "Epoch 7/10\n",
            "300/300 - 4s - 14ms/step - accuracy: 0.7880 - loss: 0.6651 - val_accuracy: 0.7801 - val_loss: 0.6716\n",
            "Epoch 8/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.7941 - loss: 0.6437 - val_accuracy: 0.7864 - val_loss: 0.6529\n",
            "Epoch 9/10\n",
            "300/300 - 4s - 14ms/step - accuracy: 0.7999 - loss: 0.6260 - val_accuracy: 0.7902 - val_loss: 0.6372\n",
            "Epoch 10/10\n",
            "300/300 - 4s - 13ms/step - accuracy: 0.8038 - loss: 0.6110 - val_accuracy: 0.7950 - val_loss: 0.6241\n",
            "Baseline Error: 20.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model changes activation function to leaky_relu from relu and changes optimizer to adagrad from adam. It results in a baseline error of 20.5% compared 11.53% of the default parameters. The MNIST dataset also did not perform well with these changes. Therefore it appears that these changes are not beneficial for these types of models. Adagrad optimizers do not perform as well as adam optimizer for high dimentional data. Both MNIST and fashion MNIST contain high dimentional inputs in the form of images. That could explain why the error is significantly higher for both."
      ],
      "metadata": {
        "id": "flKsW-8eoX9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=32, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "0KYni5jzEdJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d5d61b8-2d2b-4b21-e8e1-17a9f70fc913"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 16s - 9ms/step - accuracy: 0.8331 - loss: 0.4672 - val_accuracy: 0.8437 - val_loss: 0.4165\n",
            "Epoch 2/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.8704 - loss: 0.3548 - val_accuracy: 0.8673 - val_loss: 0.3691\n",
            "Epoch 3/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.8824 - loss: 0.3201 - val_accuracy: 0.8595 - val_loss: 0.3730\n",
            "Epoch 4/10\n",
            "1875/1875 - 21s - 11ms/step - accuracy: 0.8913 - loss: 0.2942 - val_accuracy: 0.8717 - val_loss: 0.3465\n",
            "Epoch 5/10\n",
            "1875/1875 - 20s - 10ms/step - accuracy: 0.8977 - loss: 0.2752 - val_accuracy: 0.8762 - val_loss: 0.3513\n",
            "Epoch 6/10\n",
            "1875/1875 - 21s - 11ms/step - accuracy: 0.9032 - loss: 0.2604 - val_accuracy: 0.8802 - val_loss: 0.3338\n",
            "Epoch 7/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.9080 - loss: 0.2473 - val_accuracy: 0.8874 - val_loss: 0.3196\n",
            "Epoch 8/10\n",
            "1875/1875 - 14s - 8ms/step - accuracy: 0.9110 - loss: 0.2375 - val_accuracy: 0.8802 - val_loss: 0.3460\n",
            "Epoch 9/10\n",
            "1875/1875 - 20s - 11ms/step - accuracy: 0.9161 - loss: 0.2255 - val_accuracy: 0.8830 - val_loss: 0.3518\n",
            "Epoch 10/10\n",
            "1875/1875 - 16s - 8ms/step - accuracy: 0.9194 - loss: 0.2178 - val_accuracy: 0.8932 - val_loss: 0.3134\n",
            "Baseline Error: 10.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next change is to reduce the batch size from 200 to 32. This makes training time longer but it can result in better performance since there are more updates occuring. However another downside can be more noise in the individual batches which result in more unstable training. In this case error is 10.68% from 11.53% For MNIST the error did not change but for fashion MNIST this is better. That could be because of the more freuqently updated model."
      ],
      "metadata": {
        "id": "cqhYVsNHpdZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=20, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "id": "YkkhHXMiEjds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc57492-6493-498b-c743-e400e0eebf08"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.8246 - loss: 0.5055 - val_accuracy: 0.8528 - val_loss: 0.4217\n",
            "Epoch 2/20\n",
            "300/300 - 10s - 32ms/step - accuracy: 0.8645 - loss: 0.3776 - val_accuracy: 0.8639 - val_loss: 0.3837\n",
            "Epoch 3/20\n",
            "300/300 - 6s - 19ms/step - accuracy: 0.8793 - loss: 0.3325 - val_accuracy: 0.8754 - val_loss: 0.3555\n",
            "Epoch 4/20\n",
            "300/300 - 4s - 15ms/step - accuracy: 0.8891 - loss: 0.3043 - val_accuracy: 0.8782 - val_loss: 0.3467\n",
            "Epoch 5/20\n",
            "300/300 - 5s - 17ms/step - accuracy: 0.8951 - loss: 0.2856 - val_accuracy: 0.8716 - val_loss: 0.3591\n",
            "Epoch 6/20\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.8992 - loss: 0.2728 - val_accuracy: 0.8774 - val_loss: 0.3383\n",
            "Epoch 7/20\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.9050 - loss: 0.2554 - val_accuracy: 0.8836 - val_loss: 0.3228\n",
            "Epoch 8/20\n",
            "300/300 - 5s - 15ms/step - accuracy: 0.9106 - loss: 0.2429 - val_accuracy: 0.8893 - val_loss: 0.3166\n",
            "Epoch 9/20\n",
            "300/300 - 5s - 17ms/step - accuracy: 0.9140 - loss: 0.2332 - val_accuracy: 0.8823 - val_loss: 0.3349\n",
            "Epoch 10/20\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9171 - loss: 0.2246 - val_accuracy: 0.8907 - val_loss: 0.3176\n",
            "Epoch 11/20\n",
            "300/300 - 9s - 31ms/step - accuracy: 0.9211 - loss: 0.2146 - val_accuracy: 0.8916 - val_loss: 0.3152\n",
            "Epoch 12/20\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.9223 - loss: 0.2101 - val_accuracy: 0.8927 - val_loss: 0.3110\n",
            "Epoch 13/20\n",
            "300/300 - 4s - 14ms/step - accuracy: 0.9265 - loss: 0.1982 - val_accuracy: 0.8896 - val_loss: 0.3235\n",
            "Epoch 14/20\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.9298 - loss: 0.1897 - val_accuracy: 0.8948 - val_loss: 0.3064\n",
            "Epoch 15/20\n",
            "300/300 - 5s - 15ms/step - accuracy: 0.9325 - loss: 0.1825 - val_accuracy: 0.8940 - val_loss: 0.3090\n",
            "Epoch 16/20\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.9348 - loss: 0.1778 - val_accuracy: 0.8873 - val_loss: 0.3159\n",
            "Epoch 17/20\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.9360 - loss: 0.1733 - val_accuracy: 0.8949 - val_loss: 0.3177\n",
            "Epoch 18/20\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.9399 - loss: 0.1634 - val_accuracy: 0.8916 - val_loss: 0.3220\n",
            "Epoch 19/20\n",
            "300/300 - 9s - 31ms/step - accuracy: 0.9408 - loss: 0.1602 - val_accuracy: 0.8895 - val_loss: 0.3339\n",
            "Epoch 20/20\n",
            "300/300 - 6s - 19ms/step - accuracy: 0.9434 - loss: 0.1532 - val_accuracy: 0.8957 - val_loss: 0.3259\n",
            "Baseline Error: 10.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next change increases the number of epochs to 20 from 10. for MNIST dataset this results in a lower error but for fashion mnist it results in 10.43% error from 11.53%. This could be because the model is more complex so it needs more epochs to better understand the complexity.  Notice how the validation accuracy of epoch 20 is lower than epoch 19 which is lower htan epich 18 which is lower than the highest score. Validation accuracy does not always result in a more accurate model in deployment when the differences are this small but that can be why many models use early stopping metrics to prevent overfitting."
      ],
      "metadata": {
        "id": "FoIxyzloqacH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(128, activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVbKdioYEoES",
        "outputId": "d478b016-1104-4ab3-cce4-6b7b1a9779b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.8170 - loss: 0.5248 - val_accuracy: 0.8515 - val_loss: 0.4145\n",
            "Epoch 2/10\n",
            "300/300 - 6s - 18ms/step - accuracy: 0.8670 - loss: 0.3683 - val_accuracy: 0.8669 - val_loss: 0.3687\n",
            "Epoch 3/10\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.8828 - loss: 0.3203 - val_accuracy: 0.8771 - val_loss: 0.3464\n",
            "Epoch 4/10\n",
            "300/300 - 5s - 17ms/step - accuracy: 0.8905 - loss: 0.2976 - val_accuracy: 0.8734 - val_loss: 0.3501\n",
            "Epoch 5/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.8978 - loss: 0.2770 - val_accuracy: 0.8793 - val_loss: 0.3363\n",
            "Epoch 6/10\n",
            "300/300 - 11s - 38ms/step - accuracy: 0.9047 - loss: 0.2589 - val_accuracy: 0.8868 - val_loss: 0.3101\n",
            "Epoch 7/10\n",
            "300/300 - 8s - 26ms/step - accuracy: 0.9072 - loss: 0.2490 - val_accuracy: 0.8839 - val_loss: 0.3191\n",
            "Epoch 8/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9106 - loss: 0.2377 - val_accuracy: 0.8911 - val_loss: 0.3086\n",
            "Epoch 9/10\n",
            "300/300 - 9s - 30ms/step - accuracy: 0.9160 - loss: 0.2262 - val_accuracy: 0.8810 - val_loss: 0.3274\n",
            "Epoch 10/10\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.9184 - loss: 0.2150 - val_accuracy: 0.8832 - val_loss: 0.3245\n",
            "Baseline Error: 11.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since it appears that fashion MNIST is more complex it may be expected that adding an extra dense layer may be able to handle the complexity and result in a lower error value. Just like MNIST, adding this extra layer also results in higher error values. Even if a model is more complex, adding extra layers can make the model worse due to overfitting. Based on these examples so far it demostrates how different parameter changes have varying effects on different datasets."
      ],
      "metadata": {
        "id": "i3Tv6hkTr6b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)))\n",
        " model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        " model.add(tf.keras.layers.Dropout(0.3))\n",
        " model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
        " model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        " model.add(tf.keras.layers.Dropout(0.3))\n",
        " model.add(tf.keras.layers.Flatten())\n",
        " model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        " model.add(tf.keras.layers.Dropout(0.5))\n",
        " model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh2kUNe7slad",
        "outputId": "70a8fa13-4bde-4974-a78f-5e505f32aa48"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 79s - 264ms/step - accuracy: 0.7391 - loss: 0.7073 - val_accuracy: 0.8392 - val_loss: 0.4439\n",
            "Epoch 2/10\n",
            "300/300 - 90s - 300ms/step - accuracy: 0.8343 - loss: 0.4566 - val_accuracy: 0.8619 - val_loss: 0.3779\n",
            "Epoch 3/10\n",
            "300/300 - 134s - 447ms/step - accuracy: 0.8530 - loss: 0.4055 - val_accuracy: 0.8746 - val_loss: 0.3439\n",
            "Epoch 4/10\n",
            "300/300 - 78s - 261ms/step - accuracy: 0.8648 - loss: 0.3747 - val_accuracy: 0.8816 - val_loss: 0.3231\n",
            "Epoch 5/10\n",
            "300/300 - 85s - 282ms/step - accuracy: 0.8716 - loss: 0.3509 - val_accuracy: 0.8859 - val_loss: 0.3104\n",
            "Epoch 6/10\n",
            "300/300 - 78s - 261ms/step - accuracy: 0.8766 - loss: 0.3351 - val_accuracy: 0.8917 - val_loss: 0.2936\n",
            "Epoch 7/10\n",
            "300/300 - 82s - 273ms/step - accuracy: 0.8834 - loss: 0.3228 - val_accuracy: 0.8951 - val_loss: 0.2848\n",
            "Epoch 8/10\n",
            "300/300 - 89s - 298ms/step - accuracy: 0.8862 - loss: 0.3119 - val_accuracy: 0.8993 - val_loss: 0.2749\n",
            "Epoch 9/10\n",
            "300/300 - 133s - 444ms/step - accuracy: 0.8900 - loss: 0.3018 - val_accuracy: 0.9006 - val_loss: 0.2711\n",
            "Epoch 10/10\n",
            "300/300 - 83s - 278ms/step - accuracy: 0.8921 - loss: 0.2955 - val_accuracy: 0.9035 - val_loss: 0.2618\n",
            "Baseline Error: 9.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this example a different model architecture was used. Instead of pure dense layers, convolutional layers and pooling layers are used with dropout, flatten and dense layers. Convolutional Neural Networks can be very effective when dealing with image datasets because they are typically better extracting features when compared to pure dense layers. Feature extraction is very important for the complex data of fashion MNIST so in theory this model should perform better than the previous examples. The prediction is valid as the error drops to 9.51% from 11.1%, however that is stil a high value. Fashion MNIST is very complicated and will require more advanced models and techniques as well as parameter tuning to achive a significany lower error rate. According to the fashion mnist github (https://github.com/zalandoresearch/fashion-mnist) one of the highest scoring models for mnist is a wide resnet model with 8.9 million parameters. Wide ResNets are residual netoworks with more input channels. A residual network will skip some layers and pass to deeper layers which can help performance since if a layer hurts performance as is shown by the accuracies in some of the epoch it can be skipped by the regularization. Clearly though the network must be rather deep or else key information will be missed due to the shallowness of the model. The examples here are too shallow to construct a residual network."
      ],
      "metadata": {
        "id": "FVTx33QEHcy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2\n",
        "Images with titles will lead to better classification models. This is beacause feature extraction is very important part of classifying images. Images with titles will likley be more accurate in feature extraction because it understands which features belong to each class. Without the titles, the features selected may be arbitrary and not be a set of features unique to the class. Especially when an image dataset contains similar classes, for example classifying different bird species, an unlabeled data input will likley not be able to perform well since many features extracted are shared with the other classes. It will be beneficial to identify each bird species first with labeled data so the model can learn what features differentiate it from other classes. Suppose though that an image dataset contains classes which are very different, such as identifying red apples, oranges and bananas. The model will be able to pick up the clear difference being the colors and likley will perform well unlabeled so performance may be similar compared to labeled due to the clear and dominate differences. However, more common sets are much more noisy and ambigious in relation to the classification problem. Therefore labeled images will result in better performance.  \n"
      ],
      "metadata": {
        "id": "UinA4z27EsYv"
      }
    }
  ]
}