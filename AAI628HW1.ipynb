{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urm4pGIiPhco"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code block imports some of the nessisary modules for the code.\n",
        "Tensorflow is a very popular machine learning framework. Keras provides addtional neural network modules that are built on top of tensorflow."
      ],
      "metadata": {
        "id": "tGGbWoDAfo8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Linear Regression with TensorFlow\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "m, n = housing.data.shape\n",
        "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
        "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
        "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
        "XT = tf.transpose(X)"
      ],
      "metadata": {
        "id": "8CGMAFo9RYUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(housing.DESCR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjbPuTAVgJCt",
        "outputId": "bcbbb719-d3cc-4507-d978-5e223d2cda93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block group\n",
            "        - HouseAge      median house age in block group\n",
            "        - AveRooms      average number of rooms per household\n",
            "        - AveBedrms     average number of bedrooms per household\n",
            "        - Population    block group population\n",
            "        - AveOccup      average number of household members\n",
            "        - Latitude      block group latitude\n",
            "        - Longitude     block group longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
            "\n",
            "The target variable is the median house value for California districts,\n",
            "expressed in hundreds of thousands of dollars ($100,000).\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "A household is a group of people residing within a home. Since the average\n",
            "number of rooms and bedrooms in this dataset are provided per household, these\n",
            "columns may take surprisingly large values for block groups with few households\n",
            "and many empty houses, such as vacation resorts.\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bias is set to default value of 1 for each instance. tf.constant creates a constant tensor. Tensor is the common data structure used in tensorflow."
      ],
      "metadata": {
        "id": "ZEvs2NtChCaH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta = tf.matmul(tf.matmul(tf.linalg.inv(tf.matmul(XT, X)), XT), y)\n",
        "\n",
        "print(theta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc5-J400Rbl0",
        "outputId": "3d57c1ed-417c-4ade-8701-0d6dd00d09dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-3.7144665e+01]\n",
            " [ 4.3637392e-01]\n",
            " [ 9.3933418e-03]\n",
            " [-1.0714764e-01]\n",
            " [ 6.4542186e-01]\n",
            " [-4.1016874e-06]\n",
            " [-3.7816020e-03]\n",
            " [-4.2341197e-01]\n",
            " [-4.3682083e-01]], shape=(9, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the normal equation used to minimize the cost function used in training"
      ],
      "metadata": {
        "id": "apEX3iIviwMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ad hoc mnist instances\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "# load (downloaded if needed) the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# plot 4 images as gray scale\n",
        "plt.subplot(221)\n",
        "plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(X_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(X_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.imshow(X_train[3], cmap=plt.get_cmap('gray'))\n",
        "# show the plot\n",
        "plt.show()\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "wscptX4bRePq",
        "outputId": "4d0b2679-8879-4a5d-cf61-81d3a3981b8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAGfCAYAAABhicrFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxcklEQVR4nO3de3SU9Z3H8U+CZLiYDIZLQkrAqAhdKWEXCUYooqaEWC237arHVage8RI4AvVy4kHwVqNgrcUiurWCVBHLsYFKt1gaIBxXoBKgHESywFIJQoKym0mIEDD57R8cpkZ+YzLJDPObmffrnOcc88mTZ74PJt9vnsxvnkkwxhgBAICIS4x0AQAA4AyGMgAAjmAoAwDgCIYyAACOYCgDAOAIhjIAAI5gKAMA4AiGMgAAjmAoAwDgCIYyAACOuCBcB164cKHmz5+vqqoqZWdn66WXXlJOTk6LX9fU1KTDhw8rOTlZCQkJ4SoPaBNjjOrq6pSRkaHERH6nDbW29g2J3gG3tbp3mDBYvny5SUpKMq+//rr5+OOPzd133226detmqqurW/zayspKI4mNzemtsrIyHD86ca09fcMYegdbdGwt9Y6wDOWcnBxTWFjo/7ixsdFkZGSY4uLiFr+2pqYm4v9obGwtbTU1NeH40Ylr7ekbxtA72KJja6l3hPzvb6dOnVJ5ebny8vL8WWJiovLy8rRp06Zz9m9oaFBtba1/q6urC3VJQMjx59HQCrZvSPQORKeWekfIh/IXX3yhxsZGpaWlNcvT0tJUVVV1zv7FxcXyer3+LTMzM9QlAXBcsH1DoncgNkV8pUpRUZF8Pp9/q6ysjHRJAKIAvQOxKOSrr3v06KEOHTqourq6WV5dXa309PRz9vd4PPJ4PKEuA0AUCbZvSPQOxKaQXyknJSVp6NChKi0t9WdNTU0qLS1Vbm5uqB8OQAygbwBnhOV1yrNmzdLkyZN15ZVXKicnRy+++KLq6+v1k5/8JBwPByAG0DeAMA3lm2++WZ9//rnmzJmjqqoqDRkyRGvWrDlnEQcAnEXfAKQEY4yJdBFfV1tbK6/XG+kygG/l8/mUkpIS6TLwNfQORIOWekfEV18DAIAzGMoAADiCoQwAgCMYygAAOIKhDACAIxjKAAA4gqEMAIAjGMoAADiCoQwAgCMYygAAOIKhDACAIxjKAAA4gqEMAIAjGMoAADgiLO+nDACIXUOHDrXm06ZNs+Z33HGHNV+6dKk1f+mll6z5tm3bWlFddONKGQAARzCUAQBwBEMZAABHMJQBAHBEyIfy448/roSEhGbbwIEDQ/0wAGIIfQM4Iyyrr6+44gr95S9/+ceDXMAi71Dq0KGDNfd6vSE5fqAVlF26dLHmAwYMsOaFhYXW/Pnnn7fmt956qzU/efKkNX/22Wet+RNPPGHN4Tb6hnuGDBlizdeuXWvNU1JSrLkxxprffvvt1vxHP/qRNe/evbs1jyVh+a6/4IILlJ6eHo5DA4hR9A0gTM8p7927VxkZGbrkkkt022236eDBgwH3bWhoUG1tbbMNQPwJpm9I9A7EppAP5eHDh2vJkiVas2aNFi1apAMHDuj73/++6urqrPsXFxfL6/X6t8zMzFCXBMBxwfYNid6B2BTyoVxQUKAf//jHGjx4sPLz8/Wf//mfqqmp0e9+9zvr/kVFRfL5fP6tsrIy1CUBcFywfUOidyA2hX0lRbdu3XT55Zdr37591s97PB55PJ5wlwEgirTUNyR6B2JT2Ify8ePHtX///oCr7GJR3759rXlSUpI1v/rqq635yJEjrXm3bt2s+aRJk1ouLgwOHTpkzRcsWGDNJ0yYYM0D/anyb3/7mzUvKytrRXWIRvHYNyIpJyfHmr/77rvWPNArPQKtsg70s33q1ClrHmiV9VVXXWXNA90TO9DxXRbyP18/+OCDKisr09///nd9+OGHmjBhgjp06BDw5S4AQN8Azgj5lfKhQ4d066236tixY+rZs6dGjhypzZs3q2fPnqF+KAAxgr4BnBHyobx8+fJQHxJAjKNvAGdw72sAABzBUAYAwBEJJtByuQipra0N2T2cwy3QfWHXrVtnzaPlvAJpamqy5nfeeac1P378eFDHP3LkiDX/v//7P2teUVER1PFDyefzBbzPLyIjmnpHuAW6T/2//Mu/WPM333zTmvfp08eaJyQkWPNA4yTQ6uh58+ZZ80BPZwR63NmzZ1vz4uJiax5JLfUOrpQBAHAEQxkAAEcwlAEAcARDGQAARzCUAQBwRNjvfR3LAr3f67Fjx6x5pFaGbtmyxZrX1NRY82uvvdaaB7qP7G9/+9s21QUgPF599VVrHqnblgZa9X3hhRda80D3tR89erQ1Hzx4cJvqchFXygAAOIKhDACAIxjKAAA4gqEMAIAjGMoAADiC1dft8L//+7/W/KGHHrLmN954ozXfvn27NV+wYEFQ9ezYscOa/+AHP7Dm9fX11vyKK66w5g888EBQ9QAIr6FDh1rzH/7wh9Y80L2jAwm0Cvq9996z5s8//7w1P3z4sDUP1PsC3e/+uuuus+bBnpfLuFIGAMARDGUAABzBUAYAwBEMZQAAHBH0UN64caNuuukmZWRkKCEhQStXrmz2eWOM5syZo969e6tz587Ky8vT3r17Q1UvgChE3wBaJ+jV1/X19crOztadd96piRMnnvP5efPmacGCBXrjjTeUlZWlxx57TPn5+dq9e7c6deoUkqJd982Gc9a6deuseV1dnTXPzs625nfddZc1D7TyMdAq60A+/vhjaz516tSgjgOcRd9onyFDhljztWvXWvOUlBRrboyx5n/605+seaB7ZV9zzTXWfPbs2db8tddes+aff/65Nf/b3/5mzZuamqx5oNXmge65vW3bNmvugqCHckFBgQoKCqyfM8boxRdf1OzZszVu3DhJ0tKlS5WWlqaVK1fqlltuaV+1AKISfQNonZA+p3zgwAFVVVUpLy/Pn3m9Xg0fPlybNm2yfk1DQ4Nqa2ubbQDiR1v6hkTvQGwK6VCuqqqSJKWlpTXL09LS/J/7puLiYnm9Xv+WmZkZypIAOK4tfUOidyA2RXz1dVFRkXw+n3+rrKyMdEkAogC9A7EopEM5PT1dklRdXd0sr66u9n/umzwej1JSUpptAOJHW/qGRO9AbArpva+zsrKUnp6u0tJS/2rB2tpabdmyRffdd18oHyoqBfucl8/nC2r/u+++25q/88471jzQSkbgfKJv/MPll19uzQPdT9/r9VrzL774wpofOXLEmr/xxhvW/Pjx49b8j3/8Y1B5uHXu3Nma//SnP7Xmt912WzjLaZegh/Lx48e1b98+/8cHDhzQjh07lJqaqr59+2rGjBl6+umn1b9/f/9LGzIyMjR+/PhQ1g0gitA3gNYJeihv3bpV1157rf/jWbNmSZImT56sJUuW6OGHH1Z9fb2mTp2qmpoajRw5UmvWrOG1hkAco28ArRP0UB49enTAF6BLZ95C68knn9STTz7ZrsIAxA76BtA6EV99DQAAzmAoAwDgiJCuvkZoPf7449Z86NCh1jzQ/Wi/fqekr/vzn//cproAtI/H47Hmge5ff8MNN1jzQPfNv+OOO6z51q1brXmg1cvRrm/fvpEuIWhcKQMA4AiGMgAAjmAoAwDgCIYyAACOYCgDAOAIVl87rL6+3poHusf1tm3brPmvf/1ra75+/XprHmiF5sKFC635t90UAsC5/vmf/9maB1plHci4ceOseVlZWdA1wQ1cKQMA4AiGMgAAjmAoAwDgCIYyAACOYCgDAOAIVl9Hof3791vzKVOmWPPFixdb89tvvz2ovGvXrtZ86dKl1vzIkSPWHIh3L7zwgjVPSEiw5oFWU8fbKuvERPt1ZFNT03muJHy4UgYAwBEMZQAAHMFQBgDAEQxlAAAcEfRQ3rhxo2666SZlZGQoISFBK1eubPb5KVOmKCEhodk2duzYUNULIArRN4DWCXr1dX19vbKzs3XnnXdq4sSJ1n3Gjh3bbMWvx+Npe4VotZKSEmu+d+9eax5oBej1119vzZ955hlr3q9fP2v+s5/9zJp/9tln1hyxK177xo033mjNhwwZYs0D3Uf+D3/4Q6hKimqBVlkH+nfbsWNHGKsJj6CHckFBgQoKCr51H4/Ho/T09DYXBSC20DeA1gnLc8obNmxQr169NGDAAN133306duxYwH0bGhpUW1vbbAMQf4LpGxK9A7Ep5EN57NixWrp0qUpLS/Xcc8+prKxMBQUFamxstO5fXFwsr9fr3zIzM0NdEgDHBds3JHoHYlPI7+h1yy23+P/7e9/7ngYPHqxLL71UGzZssD5XWVRUpFmzZvk/rq2t5YcLiDPB9g2J3oHYFPaXRF1yySXq0aOH9u3bZ/28x+NRSkpKsw1AfGupb0j0DsSmsN/7+tChQzp27Jh69+4d7odCALt27bLm//Zv/2bNb7rpJmse6B7a99xzjzXv37+/Nf/BD35gzYGzYqVvdO7c2ZonJSVZ86NHj1rzd955J2Q1uSTQCvvHH388qOOsW7fOmhcVFQVbUsQFPZSPHz/e7LfXAwcOaMeOHUpNTVVqaqqeeOIJTZo0Senp6dq/f78efvhhXXbZZcrPzw9p4QCiB30DaJ2gh/LWrVt17bXX+j8++5zO5MmTtWjRIu3cuVNvvPGGampqlJGRoTFjxuipp56KidccAmgb+gbQOkEP5dGjRwd8obYkvf/+++0qCEDsoW8ArcO9rwEAcARDGQAAR4R99TXcVVNTY81/+9vfWvPXXnvNml9wgf3baNSoUdZ89OjR1nzDhg3WHIgXDQ0N1vzIkSPnuZLQCrQ2YPbs2db8oYcesuaHDh2y5j//+c+t+fHjx1tRnVu4UgYAwBEMZQAAHMFQBgDAEQxlAAAcwVAGAMARrL6OA4MHD7bm//qv/2rNhw0bZs0DrbIOZPfu3dZ848aNQR0HiBd/+MMfIl1CuwwZMsSaB1pNffPNN1vzVatWWfNJkya1qa5owpUyAACOYCgDAOAIhjIAAI5gKAMA4AiGMgAAjmD1dRQaMGCANZ82bZo1nzhxojVPT08PST2NjY3WPND9epuamkLyuIDrEhISgsrHjx9vzR944IFQlRQSM2fOtOaPPfaYNfd6vdb8rbfesuZ33HFH2wqLAVwpAwDgCIYyAACOYCgDAOAIhjIAAI4IaigXFxdr2LBhSk5OVq9evTR+/HhVVFQ02+fkyZMqLCxU9+7ddeGFF2rSpEmqrq4OadEAogu9A2idoFZfl5WVqbCwUMOGDdNXX32lRx99VGPGjNHu3bvVtWtXSWdW5f3xj3/UihUr5PV6NW3aNE2cOFH/9V//FZYTiAWBVkHfeuut1jzQKuuLL744VCVZbd261Zr/7Gc/s+bRfh9fhE689g5jTFB5oF6wYMECa/76669b82PHjlnzq666yprffvvt1jw7O9ua9+nTx5ofPHjQmr///vvW/OWXX7bm8SyoobxmzZpmHy9ZskS9evVSeXm5Ro0aJZ/Pp9/85jdatmyZrrvuOknS4sWL9d3vflebN28O+A0BILbRO4DWaddzyj6fT5KUmpoqSSovL9fp06eVl5fn32fgwIHq27evNm3aZD1GQ0ODamtrm20AYhu9A7Br81BuamrSjBkzNGLECA0aNEiSVFVVpaSkJHXr1q3ZvmlpaaqqqrIep7i4WF6v179lZma2tSQAUYDeAQTW5qFcWFioXbt2afny5e0qoKioSD6fz79VVla263gA3EbvAAJr0202p02bptWrV2vjxo3NnvBPT0/XqVOnVFNT0+w33urq6oALGDwejzweT1vKABBl6B3AtwtqKBtjNH36dJWUlGjDhg3Kyspq9vmhQ4eqY8eOKi0t1aRJkyRJFRUVOnjwoHJzc0NXtePS0tKs+T/90z9Z81/96lfWfODAgSGryWbLli3WfP78+dZ81apV1px7WaMl9I7W6dChgzW///77rfnZf6tvCvT8ev/+/dtW2Dd8+OGH1nz9+vXWfM6cOSF53HgQ1FAuLCzUsmXLtGrVKiUnJ/uf6/F6vercubO8Xq/uuusuzZo1S6mpqUpJSdH06dOVm5vL6kkgjtE7gNYJaigvWrRIkjR69Ohm+eLFizVlyhRJ0i9+8QslJiZq0qRJamhoUH5+Pq9FA+IcvQNonaD/fN2STp06aeHChVq4cGGbiwIQW+gdQOtw72sAABzBUAYAwBFteklUvDl716FvevXVV635kCFDrPkll1wSqpKsAq2I/PnPf27NA92P9sSJEyGrCYhnge5G9tFHH1nzYcOGBXX8QC8XC/QKkEAC3Ss70GvJH3jggaCOj9bjShkAAEcwlAEAcARDGQAARzCUAQBwBEMZAABHxOXq6+HDh1vzhx56yJrn5ORY8+985zshq8nmyy+/tOYLFiyw5s8884w1r6+vD1lNAFrv0KFD1nzixInW/J577rHms2fPDkk9v/zlL6352TuufdO+fftC8rhoPa6UAQBwBEMZAABHMJQBAHAEQxkAAEcwlAEAcESCac17qp1HtbW18nq9YX2MZ5991poHWn0drN27d1vz1atXW/OvvvrKmge6Z3VNTU2b6kLo+Hw+paSkRLoMfM356B1Ae7XUO7hSBgDAEQxlAAAcwVAGAMARDGUAABwR1FAuLi7WsGHDlJycrF69emn8+PGqqKhots/o0aOVkJDQbLv33ntDWjSA6ELvAFonqNXXY8eO1S233KJhw4bpq6++0qOPPqpdu3Zp9+7d6tq1q6QzP1iXX365nnzySf/XdenSpdUrVVlBiWjA6uvg0DuAM1rqHUG9IcWaNWuafbxkyRL16tVL5eXlGjVqlD/v0qWL0tPTgywVQKyidwCt067nlH0+nyQpNTW1Wf7WW2+pR48eGjRokIqKigK+25EkNTQ0qLa2ttkGILbRO4AATBs1NjaaH/7wh2bEiBHN8ldffdWsWbPG7Ny507z55pvmO9/5jpkwYULA48ydO9dIYmOLqs3n87X1Ryfu0TvY4nlrqXe0eSjfe++9pl+/fqaysvJb9ystLTWSzL59+6yfP3nypPH5fP6tsrIy4v9obGwtbQzltqN3sMXz1lLvCOo55bOmTZum1atXa+PGjerTp8+37jt8+HBJZ94s+9JLLz3n8x6PRx6Ppy1lAIgy9A7g2wU1lI0xmj59ukpKSrRhwwZlZWW1+DU7duyQJPXu3btNBQKIfvQOoHWCGsqFhYVatmyZVq1apeTkZFVVVUmSvF6vOnfurP3792vZsmW64YYb1L17d+3cuVMzZ87UqFGjNHjw4LCcAAD30TuAVgrmuSAF+Bv54sWLjTHGHDx40IwaNcqkpqYaj8djLrvsMvPQQw8F9fybz+eL+N/82dha2nhOOTiB/h3pHWzxtrX0PR2Xb90ItBc3D3EPvQPRgLduBAAgSjCUAQBwBEMZAABHMJQBAHAEQxkAAEcwlAEAcARDGQAARzg3lB172TRgxfepe/h/gmjQ0vepc0O5rq4u0iUALeL71D38P0E0aOn71Lk7ejU1Nenw4cNKTk5WXV2dMjMzVVlZGRd3T6qtreV8HWeMUV1dnTIyMpSY6NzvtHGN3sH5uqy1vaNNb90YTomJif63dEtISJAkpaSkRM0/fChwvm7jVo5uondwvq5rTe/gV30AABzBUAYAwBFOD2WPx6O5c+fK4/FEupTzgvMFQiPevrc439jh3EIvAADildNXygAAxBOGMgAAjmAoAwDgCIYyAACOcHooL1y4UBdffLE6deqk4cOH669//WukSwqJjRs36qabblJGRoYSEhK0cuXKZp83xmjOnDnq3bu3OnfurLy8PO3duzcyxYZAcXGxhg0bpuTkZPXq1Uvjx49XRUVFs31OnjypwsJCde/eXRdeeKEmTZqk6urqCFWMaBarfUOKr94Rr33D2aH8zjvvaNasWZo7d662bdum7Oxs5efn6+jRo5Eurd3q6+uVnZ2thQsXWj8/b948LViwQK+88oq2bNmirl27Kj8/XydPnjzPlYZGWVmZCgsLtXnzZq1du1anT5/WmDFjVF9f799n5syZeu+997RixQqVlZXp8OHDmjhxYgSrRjSK5b4hxVfviNu+YRyVk5NjCgsL/R83NjaajIwMU1xcHMGqQk+SKSkp8X/c1NRk0tPTzfz58/1ZTU2N8Xg85u23345AhaF39OhRI8mUlZUZY86cX8eOHc2KFSv8+3zyySdGktm0aVOkykQUipe+YUz89Y546RtOXimfOnVK5eXlysvL82eJiYnKy8vTpk2bIlhZ+B04cEBVVVXNzt3r9Wr48OExc+4+n0+SlJqaKkkqLy/X6dOnm53zwIED1bdv35g5Z4RfPPcNKfZ7R7z0DSeH8hdffKHGxkalpaU1y9PS0lRVVRWhqs6Ps+cXq+fe1NSkGTNmaMSIERo0aJCkM+eclJSkbt26Nds3Vs4Z50c89w0ptntHPPUN594lCrGtsLBQu3bt0gcffBDpUgBEiXjqG05eKffo0UMdOnQ4ZxVddXW10tPTI1TV+XH2/GLx3KdNm6bVq1dr/fr1/rfYk86c86lTp1RTU9Ns/1g4Z5w/8dw3pNjtHfHWN5wcyklJSRo6dKhKS0v9WVNTk0pLS5WbmxvBysIvKytL6enpzc69trZWW7ZsidpzN8Zo2rRpKikp0bp165SVldXs80OHDlXHjh2bnXNFRYUOHjwYteeM8y+e+4YUe70jbvtGpFeaBbJ8+XLj8XjMkiVLzO7du83UqVNNt27dTFVVVaRLa7e6ujqzfft2s337diPJvPDCC2b79u3m008/NcYY8+yzz5pu3bqZVatWmZ07d5px48aZrKwsc+LEiQhX3jb33Xef8Xq9ZsOGDebIkSP+7csvv/Tvc++995q+ffuadevWma1bt5rc3FyTm5sbwaoRjWK5bxgTX70jXvuGs0PZGGNeeukl07dvX5OUlGRycnLM5s2bI11SSKxfv95IOmebPHmyMebMSxsee+wxk5aWZjwej7n++utNRUVFZItuB9u5SjKLFy/273PixAlz//33m4suush06dLFTJgwwRw5ciRyRSNqxWrfMCa+eke89g3euhEAAEc4+ZwyAADxiKEMAIAjGMoAADiCoQwAgCMYygAAOIKhDACAIxjKAAA4gqEMAIAjGMoAADiCoQwAgCOcez/lpqYmHT58WMnJyUpISIh0OUAzxhjV1dUpIyNDiYn8TusSegdc1ureEa6bav/qV78y/fr1Mx6Px+Tk5JgtW7a06usqKysD3oicjc2VrbKyMlw/OnGtrX3DGHoHW3RsLfWOsPyq/84772jWrFmaO3eutm3bpuzsbOXn5+vo0aMtfm1ycnI4SgJCiu/T0GtP35D4f4Lo0OL3aXt/s7XJyckxhYWF/o8bGxtNRkaGKS4uPmffkydPGp/P59/4bZctGjafzxeOH524FkzfMIbewRadW0u9I+RXyqdOnVJ5ebny8vL8WWJiovLy8rRp06Zz9i8uLpbX6/VvmZmZoS4JgOOC7RsSvQOxKeRD+YsvvlBjY6PS0tKa5Wlpaaqqqjpn/6KiIvl8Pv9WWVkZ6pIAOC7YviHROxCbIr762uPxyOPxRLoMAFGG3oFYFPIr5R49eqhDhw6qrq5ulldXVys9PT3UDwcgBtA3gDNCPpSTkpI0dOhQlZaW+rOmpiaVlpYqNzc31A8HIAbQN4AzwvLn61mzZmny5Mm68sorlZOToxdffFH19fX6yU9+Eo6HAxAD6BtAmIbyzTffrM8//1xz5sxRVVWVhgwZojVr1pyziAMAzqJvAFKCMcZEuoivq62tldfrjXQZwLfy+XxKSUmJdBn4GnoHokFLvYOb9wIA4AiGMgAAjmAoAwDgCIYyAACOYCgDAOAIhjIAAI5gKAMA4AiGMgAAjmAoAwDgCIYyAACOYCgDAOAIhjIAAI5gKAMA4AiGMgAAjmAoAwDgCIYyAACOYCgDAOAIhjIAAI5gKAMA4IgLQn3Axx9/XE888USzbMCAAdqzZ0+oHwpR7Prrr7fmb731ljW/5pprrHlFRUXIakLk0Dfi0+zZs635N78XzkpMtF9Hjh492pqXlZW1qa5ICvlQlqQrrrhCf/nLX/7xIBeE5WEAxBD6BhCmoXzBBRcoPT29Vfs2NDSooaHB/3FtbW04SgLguGD6hkTvQGwKy3PKe/fuVUZGhi655BLddtttOnjwYMB9i4uL5fV6/VtmZmY4SgLguGD6hkTvQGwK+VAePny4lixZojVr1mjRokU6cOCAvv/976uurs66f1FRkXw+n3+rrKwMdUkAHBds35DoHYhNIf/zdUFBgf+/Bw8erOHDh6tfv3763e9+p7vuuuuc/T0ejzweT6jLABBFgu0bEr0DsSnsKym6deumyy+/XPv27Qv3Q7XaqFGjrHn37t2teUlJSTjLiUvDhg2z5h999NF5rgQucrFvoO2mTJlizR955BFr3tTUFNTxjTHBluSssL9O+fjx49q/f7969+4d7ocCECPoG4hXIR/KDz74oMrKyvT3v/9dH374oSZMmKAOHTro1ltvDfVDAYgR9A3gjJD/+frQoUO69dZbdezYMfXs2VMjR47U5s2b1bNnz1A/FIAYQd8Azgj5UF6+fHmoDwkgxtE3gDO49zUAAI6Iy/vYBbpPav/+/a05q6/bLtC9arOysqx5v379rHlCQkLIagJwfgX6ue7UqdN5rsR9XCkDAOAIhjIAAI5gKAMA4AiGMgAAjmAoAwDgiLhcfX3HHXdY802bNp3nSmJfoNsk3n333db8zTfftOZ79uwJWU0AwiMvL8+aT58+PajjBPp5v/HGG615dXV1UMd3GVfKAAA4gqEMAIAjGMoAADiCoQwAgCMYygAAOCIuV18Huh8zQu+1114Lav+9e/eGqRIAoTJy5EhrvnjxYmvu9XqDOv78+fOt+aeffhrUcaIR0wkAAEcwlAEAcARDGQAARzCUAQBwBEMZAABHBL36euPGjZo/f77Ky8t15MgRlZSUaPz48f7PG2M0d+5c/frXv1ZNTY1GjBihRYsWqX///qGsu1UGDx5szdPS0s5zJfEr2FWXa9euDVMliKRo6hto2eTJk615RkZGUMfZsGGDNV+6dGmwJcWMoK+U6+vrlZ2drYULF1o/P2/ePC1YsECvvPKKtmzZoq5duyo/P18nT55sd7EAohN9A2idoK+UCwoKVFBQYP2cMUYvvviiZs+erXHjxkk68xtPWlqaVq5cqVtuueWcr2loaFBDQ4P/49ra2mBLAuC4UPcNid6B2BTS55QPHDigqqqqZm/f5fV6NXz48IBvi1hcXCyv1+vfMjMzQ1kSAMe1pW9I9A7EppAO5aqqKknnPmeblpbm/9w3FRUVyefz+bfKyspQlgTAcW3pGxK9A7Ep4rfZ9Hg88ng8kS4DQJShdyAWhXQop6enS5Kqq6vVu3dvf15dXa0hQ4aE8qFa5YYbbrDmnTt3Ps+VxL5AK9qzsrKCOs5nn30WinIQRVzrG/iHHj16WPM777zTmjc1NVnzmpoaa/7000+3qa5YFtI/X2dlZSk9PV2lpaX+rLa2Vlu2bFFubm4oHwpAjKBvAP8Q9JXy8ePHtW/fPv/HBw4c0I4dO5Samqq+fftqxowZevrpp9W/f39lZWXpscceU0ZGRrPXJAKIL/QNoHWCHspbt27Vtdde6/941qxZks68mHzJkiV6+OGHVV9fr6lTp6qmpkYjR47UmjVr1KlTp9BVDSCq0DeA1gl6KI8ePVrGmICfT0hI0JNPPqknn3yyXYUBiB30DaB1uPc1AACOiPhLosJpwIABQe3/8ccfh6mS2Pf8889b80Crsv/7v//bmtfV1YWsJgCtc/HFF1vzd999NyTHf+mll6z5+vXrQ3L8WMKVMgAAjmAoAwDgCIYyAACOYCgDAOAIhjIAAI6I6dXXwfroo48iXcJ5l5KSYs3Hjh1rzf/93//dmo8ZMyaox33qqaeseaB75AIIn0A/74MHDw7qOF+/VerX/fKXvwy6pnjFlTIAAI5gKAMA4AiGMgAAjmAoAwDgCIYyAACOYPX116Smpob1+NnZ2dY8ISHBmufl5VnzPn36WPOkpCRrfttttwWsKTHR/nvZiRMnrPmWLVuseUNDgzW/4AL7t1h5eXnAmgCER6D3p3722WeDOs4HH3xgzSdPnmzNfT5fUMePZ1wpAwDgCIYyAACOYCgDAOAIhjIAAI5gKAMA4IigV19v3LhR8+fPV3l5uY4cOaKSkpJmK/qmTJmiN954o9nX5Ofna82aNe0uNliBVhAbY6z5K6+8Ys0fffTRkNQT6D6ygVZff/XVV9b8yy+/tOa7d++25q+//nrAmrZu3WrNy8rKrHl1dbU1P3TokDXv3LmzNd+zZ0/AmhB7oqlvxIKLL77Ymr/77rshOf7//M//WPNA/QGtF/SVcn19vbKzs7Vw4cKA+4wdO1ZHjhzxb2+//Xa7igQQ3egbQOsEfaVcUFCggoKCb93H4/EoPT29VcdraGho9hrX2traYEsC4LhQ9w2J3oHYFJbnlDds2KBevXppwIABuu+++3Ts2LGA+xYXF8vr9fq3zMzMcJQEwHHB9A2J3oHYFPKhPHbsWC1dulSlpaV67rnnVFZWpoKCAjU2Nlr3Lyoqks/n82+VlZWhLgmA44LtGxK9A7Ep5LfZvOWWW/z//b3vfU+DBw/WpZdeqg0bNuj6668/Z3+PxyOPxxPqMgBEkWD7hkTvQGwK+72vL7nkEvXo0UP79u0L+MMVLvfff781//TTT6351VdfHc5ydPDgQWu+cuVKa/7JJ59Y882bN4eqpKBNnTrVmvfs2dOaB1qlCXybSPaNWPDII49Y86amppAcP9h7ZaP1wv465UOHDunYsWPq3bt3uB8KQIygbyBeBX2lfPz4ce3bt8//8YEDB7Rjxw6lpqYqNTVVTzzxhCZNmqT09HTt379fDz/8sC677DLl5+eHtHAA0YO+AbRO0EN569atuvbaa/0fz5o1S9KZt+xatGiRdu7cqTfeeEM1NTXKyMjQmDFj9NRTT/HcDxDH6BtA6wQ9lEePHh3wjliS9P7777erIACxh74BtA73vgYAwBFhX33toueeey7SJUStYFfChupeuwDONWTIEGs+ZsyYkBx/1apV1ryioiIkx8e5uFIGAMARDGUAABzBUAYAwBEMZQAAHMFQBgDAEXG5+hrnT0lJSaRLAGLWn//8Z2t+0UUXBXWcQPfTnzJlSrAloZ24UgYAwBEMZQAAHMFQBgDAEQxlAAAcwVAGAMARrL4GgCjVvXt3a97U1BTUcV5++WVrfvz48aBrQvtwpQwAgCMYygAAOIKhDACAIxjKAAA4gqEMAIAjglp9XVxcrN///vfas2ePOnfurKuvvlrPPfecBgwY4N/n5MmT+ulPf6rly5eroaFB+fn5evnll5WWlhby4uGOhIQEa3755Zdb80D32kVsone0z+LFi615YmJorqs+/PDDkBwH7RfU/9GysjIVFhZq8+bNWrt2rU6fPq0xY8aovr7ev8/MmTP13nvvacWKFSorK9Phw4c1ceLEkBcOIHrQO4DWCepKec2aNc0+XrJkiXr16qXy8nKNGjVKPp9Pv/nNb7Rs2TJdd911ks78hvfd735Xmzdv1lVXXXXOMRsaGtTQ0OD/uLa2ti3nAcBh9A6gddr1tw+fzydJSk1NlSSVl5fr9OnTysvL8+8zcOBA9e3bV5s2bbIeo7i4WF6v179lZma2pyQAUYDeAdi1eSg3NTVpxowZGjFihAYNGiRJqqqqUlJSkrp169Zs37S0NFVVVVmPU1RUJJ/P598qKyvbWhKAKEDvAAJr8202CwsLtWvXLn3wwQftKsDj8cjj8bTrGACiB70DCKxNQ3natGlavXq1Nm7cqD59+vjz9PR0nTp1SjU1Nc1+462urlZ6enq7i4W7jDHWPFSrQxEb6B3fbsiQIdb863/W/7pA97g+deqUNV+4cKE1r66ubrk4nBdBdUxjjKZNm6aSkhKtW7dOWVlZzT4/dOhQdezYUaWlpf6soqJCBw8eVG5ubmgqBhB16B1A6wR1pVxYWKhly5Zp1apVSk5O9j/X4/V61blzZ3m9Xt11112aNWuWUlNTlZKSounTpys3N9e6ehJAfKB3AK0T1FBetGiRJGn06NHN8sWLF2vKlCmSpF/84hdKTEzUpEmTmt0AAED8oncArRPUUA70vOHXderUSQsXLgz43AWA+EPvAFqHVTgAADiizS+JAloj0CKdJUuWnN9CgCjwzddpnxXsCvTPPvvMmj/44IPBloTzjCtlAAAcwVAGAMARDGUAABzBUAYAwBEMZQAAHMHqa4REQkJCpEsAgKjHlTIAAI5gKAMA4AiGMgAAjmAoAwDgCIYyAACOYPU1gvKnP/3Jmv/4xz8+z5UAsWfPnj3W/MMPP7TmI0eODGc5iACulAEAcARDGQAARzCUAQBwBEMZAABHMJQBAHCFCcIzzzxjrrzySnPhhReanj17mnHjxpk9e/Y02+eaa64xkppt99xzT6sfw+fznfP1bGyubT6fL5gfnbhH72BjO7O11DuCulIuKytTYWGhNm/erLVr1+r06dMaM2aM6uvrm+13991368iRI/5t3rx5wTwMgBhD7wBaJ6jXKa9Zs6bZx0uWLFGvXr1UXl6uUaNG+fMuXbooPT29VcdsaGhQQ0OD/+Pa2tpgSgIQBegdQOu06zlln88nSUpNTW2Wv/XWW+rRo4cGDRqkoqIiffnllwGPUVxcLK/X698yMzPbUxKAKEDvAOwSjDGmLV/Y1NSkH/3oR6qpqdEHH3zgz//jP/5D/fr1U0ZGhnbu3KlHHnlEOTk5+v3vf289ju23XX644Dqfz6eUlJRIlxGV6B2IZy32jjas2TDGGHPvvfeafv36mcrKym/dr7S01Egy+/bta9VxWazBFg0bC73ajt7BFs9bSBd6nTVt2jStXr1a69evV58+fb513+HDh0uS9u3b15aHAhBD6B3AtwtqoZcxRtOnT1dJSYk2bNigrKysFr9mx44dkqTevXu3qUAA0Y/eAbROUEO5sLBQy5Yt06pVq5ScnKyqqipJktfrVefOnbV//34tW7ZMN9xwg7p3766dO3dq5syZGjVqlAYPHhyWEwDgPnoH0EqtfBrIGGMC/o188eLFxhhjDh48aEaNGmVSU1ONx+Mxl112mXnooYeCev6N54XYomHjOeXgBPp3pHewxdvW0vd0m1dfh0ttba28Xm+kywC+Fauv3UPvQDRoqXdw72sAABzBUAYAwBEMZQAAHMFQBgDAEQxlAAAcwVAGAMARzg1lx16hBVjxfeoe/p8gGrT0fercUK6rq4t0CUCL+D51D/9PEA1a+j517uYhTU1NOnz4sJKTk1VXV6fMzExVVlbGxY0azr71HOfrLmOM6urqlJGRocRE536njWv0Ds7XZa3tHUHd+/p8SExM9L97TEJCgiQpJSUlav7hQ4HzdRt3jXITvYPzdV1rege/6gMA4AiGMgAAjnB6KHs8Hs2dO1cejyfSpZwXnC8QGvH2vcX5xg7nFnoBABCvnL5SBgAgnjCUAQBwBEMZAABHMJQBAHAEQxkAAEc4PZQXLlyoiy++WJ06ddLw4cP117/+NdIlhcTGjRt10003KSMjQwkJCVq5cmWzzxtjNGfOHPXu3VudO3dWXl6e9u7dG5liQ6C4uFjDhg1TcnKyevXqpfHjx6uioqLZPidPnlRhYaG6d++uCy+8UJMmTVJ1dXWEKkY0i9W+IcVX74jXvuHsUH7nnXc0a9YszZ07V9u2bVN2drby8/N19OjRSJfWbvX19crOztbChQutn583b54WLFigV155RVu2bFHXrl2Vn5+vkydPnudKQ6OsrEyFhYXavHmz1q5dq9OnT2vMmDGqr6/37zNz5ky99957WrFihcrKynT48GFNnDgxglUjGsVy35Diq3fEbd8wjsrJyTGFhYX+jxsbG01GRoYpLi6OYFWhJ8mUlJT4P25qajLp6elm/vz5/qympsZ4PB7z9ttvR6DC0Dt69KiRZMrKyowxZ86vY8eOZsWKFf59PvnkEyPJbNq0KVJlIgrFS98wJv56R7z0DSevlE+dOqXy8nLl5eX5s8TEROXl5WnTpk0RrCz8Dhw4oKqqqmbn7vV6NXz48Jg5d5/PJ0lKTU2VJJWXl+v06dPNznngwIHq27dvzJwzwi+e+4YU+70jXvqGk0P5iy++UGNjo9LS0prlaWlpqqqqilBV58fZ84vVc29qatKMGTM0YsQIDRo0SNKZc05KSlK3bt2a7Rsr54zzI577hhTbvSOe+oZzb92I2FZYWKhdu3bpgw8+iHQpAKJEPPUNJ6+Ue/TooQ4dOpyziq66ulrp6ekRqur8OHt+sXju06ZN0+rVq7V+/Xr/+95KZ8751KlTqqmpabZ/LJwzzp947htS7PaOeOsbTg7lpKQkDR06VKWlpf6sqalJpaWlys3NjWBl4ZeVlaX09PRm515bW6stW7ZE7bkbYzRt2jSVlJRo3bp1ysrKavb5oUOHqmPHjs3OuaKiQgcPHozac8b5F899Q4q93hG3fSPSK80CWb58ufF4PGbJkiVm9+7dZurUqaZbt26mqqoq0qW1W11dndm+fbvZvn27kWReeOEFs337dvPpp58aY4x59tlnTbdu3cyqVavMzp07zbhx40xWVpY5ceJEhCtvm/vuu894vV6zYcMGc+TIEf/25Zdf+ve59957Td++fc26devM1q1bTW5ursnNzY1g1YhGsdw3jImv3hGvfcPZoWyMMS+99JLp27evSUpKMjk5OWbz5s2RLikk1q9fbySds02ePNkYc+alDY899phJS0szHo/HXH/99aaioiKyRbeD7VwlmcWLF/v3OXHihLn//vvNRRddZLp06WImTJhgjhw5ErmiEbVitW8YE1+9I177Bu+nDACAI5x8ThkAgHjEUAYAwBEMZQAAHMFQBgDAEQxlAAAcwVAGAMARDGUAABzBUAYAwBEMZQAAHMFQBgDAEQxlAAAc8f+gJloYitF+zgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST dataset contains 70,000 images of handwritten digits. Shown above are examples of 5, 0 , 4, 1. Each image is of size 28x28 pixels. Therefore 784 input features and 10 classes with each class being a digit."
      ],
      "metadata": {
        "id": "gwD65coBjl0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs (0000000001, 0000000010, 0000000100 ...)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "e1wBFuLMRh0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = y_test.shape[1]\n",
        "\n",
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9mn_GQ1RlTn",
        "outputId": "624c1921-c2e3-44d1-c063-6ad40c893118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.9198 - loss: 0.2839 - val_accuracy: 0.9608 - val_loss: 0.1384\n",
            "Epoch 2/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9683 - loss: 0.1117 - val_accuracy: 0.9719 - val_loss: 0.0993\n",
            "Epoch 3/10\n",
            "300/300 - 10s - 33ms/step - accuracy: 0.9801 - loss: 0.0721 - val_accuracy: 0.9764 - val_loss: 0.0793\n",
            "Epoch 4/10\n",
            "300/300 - 9s - 31ms/step - accuracy: 0.9858 - loss: 0.0498 - val_accuracy: 0.9789 - val_loss: 0.0701\n",
            "Epoch 5/10\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.9904 - loss: 0.0365 - val_accuracy: 0.9798 - val_loss: 0.0636\n",
            "Epoch 6/10\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.9931 - loss: 0.0262 - val_accuracy: 0.9812 - val_loss: 0.0636\n",
            "Epoch 7/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9946 - loss: 0.0203 - val_accuracy: 0.9825 - val_loss: 0.0593\n",
            "Epoch 8/10\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.9965 - loss: 0.0154 - val_accuracy: 0.9822 - val_loss: 0.0579\n",
            "Epoch 9/10\n",
            "300/300 - 5s - 17ms/step - accuracy: 0.9979 - loss: 0.0103 - val_accuracy: 0.9816 - val_loss: 0.0628\n",
            "Epoch 10/10\n",
            "300/300 - 6s - 22ms/step - accuracy: 0.9987 - loss: 0.0076 - val_accuracy: 0.9818 - val_loss: 0.0632\n",
            "Baseline Error: 1.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the result with the deafault parameters of the model"
      ],
      "metadata": {
        "id": "91vMlh-ilzj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define baseline model\n",
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='leaky_relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwBsIQjhIW2i",
        "outputId": "953d2182-89f0-48cc-cf6d-7fe4b64b9f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 5s - 17ms/step - accuracy: 0.5372 - loss: 1.7507 - val_accuracy: 0.7495 - val_loss: 1.3124\n",
            "Epoch 2/10\n",
            "300/300 - 6s - 19ms/step - accuracy: 0.7840 - loss: 1.1216 - val_accuracy: 0.8252 - val_loss: 0.9331\n",
            "Epoch 3/10\n",
            "300/300 - 9s - 30ms/step - accuracy: 0.8277 - loss: 0.8616 - val_accuracy: 0.8477 - val_loss: 0.7536\n",
            "Epoch 4/10\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.8458 - loss: 0.7260 - val_accuracy: 0.8633 - val_loss: 0.6511\n",
            "Epoch 5/10\n",
            "300/300 - 9s - 30ms/step - accuracy: 0.8566 - loss: 0.6432 - val_accuracy: 0.8709 - val_loss: 0.5850\n",
            "Epoch 6/10\n",
            "300/300 - 6s - 19ms/step - accuracy: 0.8634 - loss: 0.5872 - val_accuracy: 0.8773 - val_loss: 0.5387\n",
            "Epoch 7/10\n",
            "300/300 - 10s - 33ms/step - accuracy: 0.8690 - loss: 0.5466 - val_accuracy: 0.8815 - val_loss: 0.5042\n",
            "Epoch 8/10\n",
            "300/300 - 10s - 32ms/step - accuracy: 0.8736 - loss: 0.5157 - val_accuracy: 0.8859 - val_loss: 0.4776\n",
            "Epoch 9/10\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.8778 - loss: 0.4913 - val_accuracy: 0.8887 - val_loss: 0.4564\n",
            "Epoch 10/10\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.8805 - loss: 0.4714 - val_accuracy: 0.8911 - val_loss: 0.4387\n",
            "Baseline Error: 10.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change activation function to leaky relu and optimizer to adagrad.\n",
        "ReLU activation function maps the neuron value to 0 if it is negative and does not modify it if it is positive. Leaky ReLU on the other hand, maps negative values to (ax) where a is a very small constant. This means that negative neurons are not dead neurons and still can pass information to next layers.\n",
        "Adam optimizer combines momentum and Root Mean Squared algorithims to correct the weights and biases of the network parameters.\n",
        "Adagrad independetly adapts the learning rate while optimizing.\n",
        "The results of the chages show a much worse baseline error of 10.89% when compared to the previous 1.82%. This is likley due to Adam being a better optimizer than Adagrad so it would theoretically take adagrad more epochs to achive a similar result."
      ],
      "metadata": {
        "id": "UNkKZmlhwcGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DITtHZc3IXN4",
        "outputId": "72aed008-9e29-457e-9df6-abd838212e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 - 30s - 16ms/step - accuracy: 0.9423 - loss: 0.1907 - val_accuracy: 0.9688 - val_loss: 0.1040\n",
            "Epoch 2/10\n",
            "1875/1875 - 17s - 9ms/step - accuracy: 0.9768 - loss: 0.0753 - val_accuracy: 0.9750 - val_loss: 0.0710\n",
            "Epoch 3/10\n",
            "1875/1875 - 21s - 11ms/step - accuracy: 0.9847 - loss: 0.0483 - val_accuracy: 0.9793 - val_loss: 0.0658\n",
            "Epoch 4/10\n",
            "1875/1875 - 17s - 9ms/step - accuracy: 0.9887 - loss: 0.0344 - val_accuracy: 0.9817 - val_loss: 0.0634\n",
            "Epoch 5/10\n",
            "1875/1875 - 17s - 9ms/step - accuracy: 0.9916 - loss: 0.0245 - val_accuracy: 0.9811 - val_loss: 0.0682\n",
            "Epoch 6/10\n",
            "1875/1875 - 19s - 10ms/step - accuracy: 0.9933 - loss: 0.0197 - val_accuracy: 0.9804 - val_loss: 0.0708\n",
            "Epoch 7/10\n",
            "1875/1875 - 19s - 10ms/step - accuracy: 0.9944 - loss: 0.0170 - val_accuracy: 0.9810 - val_loss: 0.0777\n",
            "Epoch 8/10\n",
            "1875/1875 - 19s - 10ms/step - accuracy: 0.9956 - loss: 0.0135 - val_accuracy: 0.9805 - val_loss: 0.0741\n",
            "Epoch 9/10\n",
            "1875/1875 - 23s - 12ms/step - accuracy: 0.9957 - loss: 0.0125 - val_accuracy: 0.9778 - val_loss: 0.0928\n",
            "Epoch 10/10\n",
            "1875/1875 - 18s - 9ms/step - accuracy: 0.9963 - loss: 0.0114 - val_accuracy: 0.9818 - val_loss: 0.0856\n",
            "Baseline Error: 1.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the default parameters where reverted back and now the batch size was changed to 32 from 200. This results in much more computations as shown by the time to complete each epoch. Even though the time per step is lower overall time increases by factor of 2x-6x. This though does not result in a meaningful change as the error is the same. Therefore it is better to have higher batch size in this case."
      ],
      "metadata": {
        "id": "gLl80ByJ0wnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3bogEWCMwRl",
        "outputId": "bb7c9449-92da-4b73-bdda-d91ad306bb21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "300/300 - 13s - 42ms/step - accuracy: 0.9206 - loss: 0.2785 - val_accuracy: 0.9581 - val_loss: 0.1482\n",
            "Epoch 2/20\n",
            "300/300 - 16s - 54ms/step - accuracy: 0.9681 - loss: 0.1107 - val_accuracy: 0.9734 - val_loss: 0.0923\n",
            "Epoch 3/20\n",
            "300/300 - 9s - 29ms/step - accuracy: 0.9796 - loss: 0.0708 - val_accuracy: 0.9781 - val_loss: 0.0722\n",
            "Epoch 4/20\n",
            "300/300 - 6s - 20ms/step - accuracy: 0.9857 - loss: 0.0511 - val_accuracy: 0.9780 - val_loss: 0.0677\n",
            "Epoch 5/20\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.9892 - loss: 0.0372 - val_accuracy: 0.9798 - val_loss: 0.0615\n",
            "Epoch 6/20\n",
            "300/300 - 9s - 31ms/step - accuracy: 0.9928 - loss: 0.0269 - val_accuracy: 0.9801 - val_loss: 0.0616\n",
            "Epoch 7/20\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9953 - loss: 0.0194 - val_accuracy: 0.9813 - val_loss: 0.0567\n",
            "Epoch 8/20\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.9964 - loss: 0.0153 - val_accuracy: 0.9812 - val_loss: 0.0591\n",
            "Epoch 9/20\n",
            "300/300 - 7s - 23ms/step - accuracy: 0.9977 - loss: 0.0110 - val_accuracy: 0.9823 - val_loss: 0.0562\n",
            "Epoch 10/20\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.9989 - loss: 0.0074 - val_accuracy: 0.9820 - val_loss: 0.0583\n",
            "Epoch 11/20\n",
            "300/300 - 5s - 17ms/step - accuracy: 0.9994 - loss: 0.0053 - val_accuracy: 0.9819 - val_loss: 0.0593\n",
            "Epoch 12/20\n",
            "300/300 - 6s - 21ms/step - accuracy: 0.9995 - loss: 0.0040 - val_accuracy: 0.9828 - val_loss: 0.0602\n",
            "Epoch 13/20\n",
            "300/300 - 10s - 33ms/step - accuracy: 0.9998 - loss: 0.0028 - val_accuracy: 0.9830 - val_loss: 0.0591\n",
            "Epoch 14/20\n",
            "300/300 - 9s - 30ms/step - accuracy: 0.9996 - loss: 0.0033 - val_accuracy: 0.9810 - val_loss: 0.0681\n",
            "Epoch 15/20\n",
            "300/300 - 7s - 22ms/step - accuracy: 0.9972 - loss: 0.0094 - val_accuracy: 0.9802 - val_loss: 0.0759\n",
            "Epoch 16/20\n",
            "300/300 - 5s - 16ms/step - accuracy: 0.9957 - loss: 0.0128 - val_accuracy: 0.9802 - val_loss: 0.0696\n",
            "Epoch 17/20\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9816 - val_loss: 0.0719\n",
            "Epoch 18/20\n",
            "300/300 - 10s - 32ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9852 - val_loss: 0.0593\n",
            "Epoch 19/20\n",
            "300/300 - 7s - 22ms/step - accuracy: 1.0000 - loss: 5.6795e-04 - val_accuracy: 0.9852 - val_loss: 0.0600\n",
            "Epoch 20/20\n",
            "300/300 - 5s - 16ms/step - accuracy: 1.0000 - loss: 4.0746e-04 - val_accuracy: 0.9844 - val_loss: 0.0612\n",
            "Baseline Error: 1.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the deafault parameters are reverted but epochs are set to 20 from 10. As expected this decareases the baseline error. However we can see the loss becoming marginally small so if epochs were increased even more to 100 for example it would not be significantly better but would incure significant computational costs. This is why many models employ early stopping so when the loss becomes small enough the model stops running epochs as the amount is different for each model."
      ],
      "metadata": {
        "id": "DqpaOXem1yYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_model():\n",
        "# create model\n",
        " model = Sequential()\n",
        " model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        " model.add(Dense(128, activation='relu'))\n",
        " model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
        "# Compile model\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " return model\n",
        "\n",
        "\n",
        "# build the model\n",
        "model = baseline_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi3oeJdcSUHW",
        "outputId": "0212ab67-a3aa-43c7-8ce6-8dc769b1ff85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "300/300 - 9s - 29ms/step - accuracy: 0.9199 - loss: 0.2888 - val_accuracy: 0.9588 - val_loss: 0.1393\n",
            "Epoch 2/10\n",
            "300/300 - 7s - 23ms/step - accuracy: 0.9710 - loss: 0.0989 - val_accuracy: 0.9712 - val_loss: 0.0907\n",
            "Epoch 3/10\n",
            "300/300 - 12s - 40ms/step - accuracy: 0.9806 - loss: 0.0637 - val_accuracy: 0.9777 - val_loss: 0.0716\n",
            "Epoch 4/10\n",
            "300/300 - 7s - 23ms/step - accuracy: 0.9873 - loss: 0.0411 - val_accuracy: 0.9792 - val_loss: 0.0665\n",
            "Epoch 5/10\n",
            "300/300 - 10s - 34ms/step - accuracy: 0.9914 - loss: 0.0284 - val_accuracy: 0.9788 - val_loss: 0.0673\n",
            "Epoch 6/10\n",
            "300/300 - 11s - 36ms/step - accuracy: 0.9938 - loss: 0.0206 - val_accuracy: 0.9776 - val_loss: 0.0754\n",
            "Epoch 7/10\n",
            "300/300 - 11s - 37ms/step - accuracy: 0.9952 - loss: 0.0158 - val_accuracy: 0.9803 - val_loss: 0.0699\n",
            "Epoch 8/10\n",
            "300/300 - 5s - 18ms/step - accuracy: 0.9965 - loss: 0.0114 - val_accuracy: 0.9816 - val_loss: 0.0651\n",
            "Epoch 9/10\n",
            "300/300 - 8s - 25ms/step - accuracy: 0.9961 - loss: 0.0116 - val_accuracy: 0.9833 - val_loss: 0.0624\n",
            "Epoch 10/10\n",
            "300/300 - 8s - 28ms/step - accuracy: 0.9956 - loss: 0.0131 - val_accuracy: 0.9766 - val_loss: 0.0923\n",
            "Baseline Error: 2.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the parameters are set back to default values and an extra dense layer is added to test the theory that deeper networks are always better. 128 is chosen as an arbirtary amount between num_pixels which is 784 and num classes which is 10. It keeps the same activation function as default. Here we can see that the error is more than the previous. This is likley due to overfitting the dataset since there are too many neurons and layers. This can be a very difficult value to test due to the amount of layers, types of layers and number of neurons per layer as well as other parameters."
      ],
      "metadata": {
        "id": "VJHs3a8R3Wq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall there are many different parameters to be tuned for models. Here parameters were tested manually and compared for better understanding. However there are functions such as GridSearchCV as well as others that are used to test various combinations of hyperparameters automatically and return the model with the best result."
      ],
      "metadata": {
        "id": "6MPLlkZf3XV6"
      }
    }
  ]
}